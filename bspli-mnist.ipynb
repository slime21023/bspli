{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist dtype: float32\n",
      "mnist data shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./Bspli/\")\n",
    "import os  \n",
    "import faiss\n",
    "import time\n",
    "import numpy as np \n",
    "import index \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "mnist = np.load(\"dataset/mnist-784-euclidean.npy\")\n",
    "print(f'mnist data shape: {mnist.shape}')\n",
    "print(f'mnist dtype: {mnist.dtype}')\n",
    "\n",
    "# mnist = np.random.rand(10000, 784)\n",
    "# mnist = mnist.astype(np.float32)\n",
    "# print(f'mnist dtype: {mnist.dtype}')\n",
    "# print(f'mnist data shape: {mnist.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute query: [[   0   97   92  930 7294 5918 5574 7534 7898 7353 7805 4977 2402 4335\n",
      "  5740  742 1694 7398 6924 1809 7768 1765 1705 7050 9970 1563 4375 8846\n",
      "  4146 9821 8130 4459 9441 6375 8178 9050 9344   98 3419 6708 6755 8030\n",
      "  3356 5395 5786 5818 6009 8861 7201 2588 4152 4261 4102 1271 1134 9227\n",
      "  2285 2659 3237 4980 5414 8104 2515 7543 1966 3828  728  164  589 7941\n",
      "   802 4163  855 2850 7735  873 3057 9772 3865 1536 8209 6874 4230 9466\n",
      "  1920 7733 5842 6583 6016  615 6149  493 9678 6123 2618 7143 3463 5479\n",
      "  4507  467]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Brute Search\n",
    "flat = faiss.IndexFlatL2(mnist.shape[1])\n",
    "flat.add(mnist)\n",
    "\n",
    "D, FLAT_I = flat.search(mnist[0].reshape(1, mnist.shape[1]), k=100) \n",
    "print(f'brute query: {FLAT_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist tensor shape: torch.Size([10000, 784])\n",
      "torch.Size([10000, 785])\n",
      "first stage partitioning finish\n",
      "partitioning blocks : 1\n",
      "training local model\n",
      "trainging global model\n",
      "global index train smaple count: 17\n",
      "finish\n",
      "local model len:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\bspli\\./Bspli\\utils\\Partitioning.py:113: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ma = torch.tensor(means)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    }
   ],
   "source": [
    "mnist_tensor = torch.from_numpy(mnist)\n",
    "print(f'mnist tensor shape: {mnist_tensor.shape}')\n",
    "\n",
    "idx = index.Indexing(\n",
    "    gl_size=80000, \n",
    "    ll_size=1000,\n",
    "    g_epoch_num=5,\n",
    "    l_epoch_num=20,\n",
    "    g_hidden_size=5,\n",
    "    l_hidden_size=10,\n",
    "    l_block_range=60,\n",
    "    random_partitioning=False\n",
    ")\n",
    "idx.train(mnist_tensor)\n",
    "\n",
    "print(f\"local model len:{len(idx._l_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.83\n",
      "pred: tensor([   0,   97,  930, 7294, 5918, 7534, 7898, 7353, 7805, 4977, 4335, 5740,\n",
      "         742, 1694, 7398, 6924, 1809, 1765, 1705, 9970, 1563, 4375, 8846, 4146,\n",
      "        9821, 8130, 4459, 9441, 6375, 9050, 9344,   98, 3419, 6708, 8030, 3356,\n",
      "        5395, 5786, 5818, 6009, 8861, 7201, 2588, 4152, 4261, 4102, 1271, 9227,\n",
      "        2285, 2659, 4980, 8104, 2515, 7543, 1966, 3828,  728, 7941,  802, 4163,\n",
      "         855, 2850, 7735,  873, 3865, 1536, 6874, 9466, 1920, 7733, 5842, 6583,\n",
      "        6016,  615, 6149,  493, 9678, 6123, 2618, 7143, 5479, 4507,  467, 7028,\n",
      "        4932, 4563,  189, 6093, 3323, 3667,  653, 5229, 8745, 8192, 9786, 9055,\n",
      "        7001, 4297, 2763,  645], dtype=torch.int32)\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "qp = torch.from_numpy(mnist[0])\n",
    "# print(qp)\n",
    "pred = idx.query(qp, k=100)\n",
    "print(f\"recall: {recall(pred, FLAT_I)}\")\n",
    "\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def benchmark_knn_query(data, index, size=1000, k=100):\n",
    "    indices = np.random.choice(data.shape[0], size, replace=False)\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "    result.append((query_time/1000, cur_recall/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall(pred, FLAT_I)\n",
    "\n",
    "benchmark_knn_query(mnist, idx, size=1000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.012954625129699707, 0.8198499999999997)]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
