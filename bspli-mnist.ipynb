{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist data shape: (60000, 784)\n",
      "mnist dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./Bspli/\")\n",
    "import os  \n",
    "import faiss\n",
    "import time\n",
    "import numpy as np \n",
    "import index \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "mnist = np.load(\"dataset/mnist-784-euclidean.npy\")\n",
    "print(f'mnist data shape: {mnist.shape}')\n",
    "print(f'mnist dtype: {mnist.dtype}')\n",
    "\n",
    "# mnist = np.random.uniform(low=0, high=255, size=(100000, 2))\n",
    "# mnist = mnist.astype(np.float32)\n",
    "# print(f'mnist dtype: {mnist.dtype}')\n",
    "# print(f'mnist data shape: {mnist.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute query: [[    0 32248  8728 18932 30483 24149 42338 52295 26251 50173 53634 24330\n",
      "  54159 57528  1482 53428 18123 31379 52864 10536 29719 36087 30489 23947\n",
      "  20034 52057 33825 21654 31008 55208 22477 44282 47968 54203 19825  1634\n",
      "  27378 33909 15378 24708 34474 26413 16017 46824 46358  1516 34557 16832\n",
      "  21629 29021 10740 24107  5688 52665  1864  5036 39031  1978 40546 22322\n",
      "  52231 37284 24730  5970 21976 16945  9568 36697 25675 54189 11396 42555\n",
      "  33445 52540 44263 18404 19186 24232 54184 25762 14736 33970  5210 59212\n",
      "   8642 22569 15052  2933  6772 22963  6516   832 21244 21583 35838 59846\n",
      "  21210 13502 52559 13862]]\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 70.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Brute Search\n",
    "flat = faiss.IndexFlatL2(mnist.shape[1])\n",
    "flat.add(mnist)\n",
    "\n",
    "D, FLAT_I = flat.search(mnist[0].reshape(1, mnist.shape[1]), k=100) \n",
    "print(f'brute query: {FLAT_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist tensor shape: torch.Size([60000, 784])\n",
      "torch.Size([1995, 785])\n",
      "torch.Size([8906, 785])\n",
      "torch.Size([4610, 785])\n",
      "torch.Size([3738, 785])\n",
      "torch.Size([7329, 785])\n",
      "torch.Size([4915, 785])\n",
      "torch.Size([8447, 785])\n",
      "torch.Size([4660, 785])\n",
      "torch.Size([2740, 785])\n",
      "torch.Size([2620, 785])\n",
      "torch.Size([382, 785])\n",
      "torch.Size([9658, 785])\n",
      "first stage partitioning finish\n",
      "partitioning blocks : 12\n",
      "training local model\n",
      "1, 10 loss: -0.0\n",
      "2, 10 loss: -0.0\n",
      "3, 10 loss: -0.0\n",
      "4, 10 loss: -0.0\n",
      "5, 10 loss: -0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6, 10 loss: -0.0\n",
      "7, 10 loss: -0.0\n",
      "8, 10 loss: -0.0\n",
      "9, 10 loss: -0.0\n",
      "10, 10 loss: -0.0\n",
      "training local model\n",
      "1, 10 loss: 0.008268425464630127\n",
      "1, 20 loss: 0.007569401264190674\n",
      "1, 30 loss: 0.006799876689910889\n",
      "1, 40 loss: 0.00661792516708374\n",
      "2, 10 loss: 0.0064057749509811406\n",
      "2, 20 loss: 0.006753825545310974\n",
      "2, 30 loss: 0.006496251821517945\n",
      "2, 40 loss: 0.006218312382698059\n",
      "3, 10 loss: 0.006364407539367675\n",
      "3, 20 loss: 0.006230348348617553\n",
      "3, 30 loss: 0.006246569156646728\n",
      "3, 40 loss: 0.006174065470695496\n",
      "4, 10 loss: 0.0061866134405136105\n",
      "4, 20 loss: 0.0059846508502960204\n",
      "4, 30 loss: 0.005865477919578552\n",
      "4, 40 loss: 0.006033384203910828\n",
      "5, 10 loss: 0.005967954993247986\n",
      "5, 20 loss: 0.006024157404899597\n",
      "5, 30 loss: 0.006035679578781128\n",
      "5, 40 loss: 0.006016644239425659\n",
      "6, 10 loss: 0.005849908590316772\n",
      "6, 20 loss: 0.006007859110832214\n",
      "6, 30 loss: 0.006205464005470276\n",
      "6, 40 loss: 0.005943137407302857\n",
      "7, 10 loss: 0.005731755495071411\n",
      "7, 20 loss: 0.0060200560092926025\n",
      "7, 30 loss: 0.005847260951995849\n",
      "7, 40 loss: 0.005965259075164795\n",
      "8, 10 loss: 0.005815929174423218\n",
      "8, 20 loss: 0.005932068824768067\n",
      "8, 30 loss: 0.005780115723609924\n",
      "8, 40 loss: 0.00582859218120575\n",
      "9, 10 loss: 0.005974797010421753\n",
      "9, 20 loss: 0.0058196157217025755\n",
      "9, 30 loss: 0.00581520140171051\n",
      "9, 40 loss: 0.005984475612640381\n",
      "10, 10 loss: 0.0059157729148864744\n",
      "10, 20 loss: 0.00572216272354126\n",
      "10, 30 loss: 0.0058045613765716556\n",
      "10, 40 loss: 0.0058698391914367674\n",
      "training local model\n",
      "1, 10 loss: 0.0025474902987480163\n",
      "1, 20 loss: 0.0022477102279663086\n",
      "2, 10 loss: 0.002251150906085968\n",
      "2, 20 loss: 0.0020898981392383576\n",
      "3, 10 loss: 0.0020838160812854767\n",
      "3, 20 loss: 0.0020231983065605165\n",
      "4, 10 loss: 0.0020106737315654754\n",
      "4, 20 loss: 0.0021825996041297912\n",
      "5, 10 loss: 0.0021439000964164736\n",
      "5, 20 loss: 0.002065781205892563\n",
      "6, 10 loss: 0.0019744545221328734\n",
      "6, 20 loss: 0.0019987235963344575\n",
      "7, 10 loss: 0.0019586411118507384\n",
      "7, 20 loss: 0.0019838903844356538\n",
      "8, 10 loss: 0.0019526618719100952\n",
      "8, 20 loss: 0.0018998736143112183\n",
      "9, 10 loss: 0.0019073750078678132\n",
      "9, 20 loss: 0.0020076149702072145\n",
      "10, 10 loss: 0.0019723327457904817\n",
      "10, 20 loss: 0.0020748606324195863\n",
      "training local model\n",
      "1, 10 loss: 0.0024459166824817658\n",
      "2, 10 loss: 0.002394251376390457\n",
      "3, 10 loss: 0.0020138843357563017\n",
      "4, 10 loss: 0.002062564790248871\n",
      "5, 10 loss: 0.0020415617525577547\n",
      "6, 10 loss: 0.001972227543592453\n",
      "7, 10 loss: 0.0020026324689388277\n",
      "8, 10 loss: 0.001966082900762558\n",
      "9, 10 loss: 0.0020403560996055605\n",
      "10, 10 loss: 0.0019487115740776063\n",
      "training local model\n",
      "1, 10 loss: 0.0076837104558944705\n",
      "1, 20 loss: 0.007432358264923096\n",
      "1, 30 loss: 0.0068331223726272585\n",
      "2, 10 loss: 0.006582196950912476\n",
      "2, 20 loss: 0.006454005241394043\n",
      "2, 30 loss: 0.006212035417556763\n",
      "3, 10 loss: 0.006206821203231811\n",
      "3, 20 loss: 0.005884506106376648\n",
      "3, 30 loss: 0.006128445267677307\n",
      "4, 10 loss: 0.005785583257675171\n",
      "4, 20 loss: 0.0060495007038116454\n",
      "4, 30 loss: 0.005987575054168701\n",
      "5, 10 loss: 0.005779956579208374\n",
      "5, 20 loss: 0.006018496155738831\n",
      "5, 30 loss: 0.005935975909233093\n",
      "6, 10 loss: 0.0059597504138946536\n",
      "6, 20 loss: 0.005704902410507202\n",
      "6, 30 loss: 0.0058240056037902836\n",
      "7, 10 loss: 0.005707783102989197\n",
      "7, 20 loss: 0.0056538724899291995\n",
      "7, 30 loss: 0.005839764475822449\n",
      "8, 10 loss: 0.00554639458656311\n",
      "8, 20 loss: 0.005482501983642578\n",
      "8, 30 loss: 0.0057508420944213864\n",
      "9, 10 loss: 0.005575439929962158\n",
      "9, 20 loss: 0.005657447576522827\n",
      "9, 30 loss: 0.005591030716896057\n",
      "10, 10 loss: 0.005611300468444824\n",
      "10, 20 loss: 0.005385004281997681\n",
      "10, 30 loss: 0.005618199706077576\n",
      "training local model\n",
      "1, 10 loss: 0.004132022857666015\n",
      "1, 20 loss: 0.0036701229214668274\n",
      "2, 10 loss: 0.0034543687105178834\n",
      "2, 20 loss: 0.0035776111483573915\n",
      "3, 10 loss: 0.0034167683124542237\n",
      "3, 20 loss: 0.0032902732491493225\n",
      "4, 10 loss: 0.003461503088474274\n",
      "4, 20 loss: 0.0032696709036827087\n",
      "5, 10 loss: 0.0032729968428611756\n",
      "5, 20 loss: 0.0032694268226623534\n",
      "6, 10 loss: 0.003196244239807129\n",
      "6, 20 loss: 0.003156067132949829\n",
      "7, 10 loss: 0.0032879963517189028\n",
      "7, 20 loss: 0.003152286112308502\n",
      "8, 10 loss: 0.0031843972206115722\n",
      "8, 20 loss: 0.0031906965374946593\n",
      "9, 10 loss: 0.0032016968727111815\n",
      "9, 20 loss: 0.0031691664457321168\n",
      "10, 10 loss: 0.0032458418607711793\n",
      "10, 20 loss: 0.0031955993175506593\n",
      "training local model\n",
      "1, 10 loss: 0.007502592206001282\n",
      "1, 20 loss: 0.007024280428886413\n",
      "1, 30 loss: 0.006509633660316467\n",
      "1, 40 loss: 0.00684195876121521\n",
      "2, 10 loss: 0.006819617748260498\n",
      "2, 20 loss: 0.00635296106338501\n",
      "2, 30 loss: 0.00664793848991394\n",
      "2, 40 loss: 0.006518364548683166\n",
      "3, 10 loss: 0.00647464394569397\n",
      "3, 20 loss: 0.006403721570968628\n",
      "3, 30 loss: 0.006460087299346924\n",
      "3, 40 loss: 0.006192023754119873\n",
      "4, 10 loss: 0.006399716138839722\n",
      "4, 20 loss: 0.0059826219081878665\n",
      "4, 30 loss: 0.006347813606262207\n",
      "4, 40 loss: 0.006255685687065125\n",
      "5, 10 loss: 0.006184830665588379\n",
      "5, 20 loss: 0.006380574703216553\n",
      "5, 30 loss: 0.0061261171102523805\n",
      "5, 40 loss: 0.0063569372892379765\n",
      "6, 10 loss: 0.006293893456459045\n",
      "6, 20 loss: 0.00605180561542511\n",
      "6, 30 loss: 0.006131991744041443\n",
      "6, 40 loss: 0.006162652969360352\n",
      "7, 10 loss: 0.006014702320098877\n",
      "7, 20 loss: 0.006211182475090027\n",
      "7, 30 loss: 0.006368182897567749\n",
      "7, 40 loss: 0.006088941097259521\n",
      "8, 10 loss: 0.005981070399284363\n",
      "8, 20 loss: 0.006146396398544311\n",
      "8, 30 loss: 0.005847359895706177\n",
      "8, 40 loss: 0.00606174111366272\n",
      "9, 10 loss: 0.005947898626327514\n",
      "9, 20 loss: 0.005697634220123291\n",
      "9, 30 loss: 0.005759309530258178\n",
      "9, 40 loss: 0.0057859492301940915\n",
      "10, 10 loss: 0.005927811861038208\n",
      "10, 20 loss: 0.005762125253677368\n",
      "10, 30 loss: 0.005624831914901734\n",
      "10, 40 loss: 0.005817617774009704\n",
      "training local model\n",
      "1, 10 loss: 0.005680632591247558\n",
      "1, 20 loss: 0.005305688381195068\n",
      "2, 10 loss: 0.005080654621124268\n",
      "2, 20 loss: 0.0049080437421798705\n",
      "3, 10 loss: 0.004591943621635437\n",
      "3, 20 loss: 0.004514236748218536\n",
      "4, 10 loss: 0.004281045496463775\n",
      "4, 20 loss: 0.004424251317977905\n",
      "5, 10 loss: 0.004340939819812774\n",
      "5, 20 loss: 0.004211563467979431\n",
      "6, 10 loss: 0.004146202206611633\n",
      "6, 20 loss: 0.004195351004600525\n",
      "7, 10 loss: 0.004175704121589661\n",
      "7, 20 loss: 0.0041097202897071835\n",
      "8, 10 loss: 0.004074333906173706\n",
      "8, 20 loss: 0.004083112776279449\n",
      "9, 10 loss: 0.004046746790409088\n",
      "9, 20 loss: 0.0039851745963096616\n",
      "10, 10 loss: 0.003997060060501098\n",
      "10, 20 loss: 0.004006801545619965\n",
      "training local model\n",
      "1, 10 loss: -0.0\n",
      "2, 10 loss: -0.0\n",
      "3, 10 loss: -0.0\n",
      "4, 10 loss: -0.0\n",
      "5, 10 loss: -0.0\n",
      "6, 10 loss: -0.0\n",
      "7, 10 loss: -0.0\n",
      "8, 10 loss: -0.0\n",
      "9, 10 loss: -0.0\n",
      "10, 10 loss: -0.0\n",
      "training local model\n",
      "1, 10 loss: -0.0\n",
      "2, 10 loss: -0.0\n",
      "3, 10 loss: -0.0\n",
      "4, 10 loss: -0.0\n",
      "5, 10 loss: -0.0\n",
      "6, 10 loss: -0.0\n",
      "7, 10 loss: -0.0\n",
      "8, 10 loss: -0.0\n",
      "9, 10 loss: -0.0\n",
      "10, 10 loss: -0.0\n",
      "training local model\n",
      "training local model\n",
      "1, 10 loss: 0.008207777142524719\n",
      "1, 20 loss: 0.0077878344058990474\n",
      "1, 30 loss: 0.0072403204441070556\n",
      "1, 40 loss: 0.007145191431045532\n",
      "2, 10 loss: 0.00689473032951355\n",
      "2, 20 loss: 0.007063761949539184\n",
      "2, 30 loss: 0.006650610566139221\n",
      "2, 40 loss: 0.00687580943107605\n",
      "3, 10 loss: 0.006687883734703064\n",
      "3, 20 loss: 0.0065251123905181885\n",
      "3, 30 loss: 0.006769639849662781\n",
      "3, 40 loss: 0.006697037220001221\n",
      "4, 10 loss: 0.006386162042617798\n",
      "4, 20 loss: 0.00619297206401825\n",
      "4, 30 loss: 0.0065691864490509035\n",
      "4, 40 loss: 0.006391289234161377\n",
      "5, 10 loss: 0.00652927577495575\n",
      "5, 20 loss: 0.006244654655456543\n",
      "5, 30 loss: 0.006522752642631531\n",
      "5, 40 loss: 0.006633099913597107\n",
      "6, 10 loss: 0.00638816773891449\n",
      "6, 20 loss: 0.00655312716960907\n",
      "6, 30 loss: 0.00609163761138916\n",
      "6, 40 loss: 0.006366826891899109\n",
      "7, 10 loss: 0.006343402266502381\n",
      "7, 20 loss: 0.006370456218719483\n",
      "7, 30 loss: 0.006604202389717102\n",
      "7, 40 loss: 0.006311830282211304\n",
      "8, 10 loss: 0.006261265873908997\n",
      "8, 20 loss: 0.006355964541435242\n",
      "8, 30 loss: 0.006145694255828857\n",
      "8, 40 loss: 0.006360076665878296\n",
      "9, 10 loss: 0.00606252908706665\n",
      "9, 20 loss: 0.00609287440776825\n",
      "9, 30 loss: 0.006366776823997497\n",
      "9, 40 loss: 0.006354542374610901\n",
      "10, 10 loss: 0.006367725729942322\n",
      "10, 20 loss: 0.0063707435131073\n",
      "10, 30 loss: 0.006201350688934326\n",
      "10, 40 loss: 0.006215546131134033\n",
      "trainging global model\n",
      "global index train smaple count: 84\n",
      "1, 10 loss: 0.8992422485351562\n",
      "2, 10 loss: 0.3761532211303711\n",
      "3, 10 loss: 0.9761660766601562\n",
      "4, 10 loss: 0.3961936950683594\n",
      "5, 10 loss: 0.4897042465209961\n",
      "finish\n",
      "local model len:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\bspli\\./Bspli\\utils\\Partitioning.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ma = torch.tensor(means)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    }
   ],
   "source": [
    "mnist_tensor = torch.from_numpy(mnist)\n",
    "print(f'mnist tensor shape: {mnist_tensor.shape}')\n",
    "\n",
    "idx = index.Indexing(\n",
    "    gl_size=10000, \n",
    "    ll_size=3000,\n",
    "    g_epoch_num=5,\n",
    "    l_epoch_num=10,\n",
    "    g_hidden_size=10,\n",
    "    l_hidden_size=20,\n",
    "    g_block_range=4,\n",
    "    l_block_range=4,\n",
    "    random_partitioning=False\n",
    ")\n",
    "idx.train(mnist_tensor)\n",
    "\n",
    "print(f\"local model len:{len(idx._l_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.17\n",
      "pred: tensor([ 8728, 52295, 23947, 21654, 44282, 54203, 24708, 46824, 24107,  5036,\n",
      "        22322, 21976, 36697, 25675, 25762, 14736, 22569, 43997, 53812, 15975,\n",
      "        24271, 15907, 15444,  2395, 49334, 29023, 26364, 36242, 25557,  8230,\n",
      "        24017, 11221, 45432, 22542, 33607, 43067, 25623, 54283, 52310, 42971,\n",
      "        24281,  2037, 25720,  6274, 38240, 21144, 47090, 15482, 26328, 16013,\n",
      "        17608,  2038, 57765, 24119, 20439, 55151, 48965, 59352, 20018, 55325,\n",
      "        23341, 24651, 11097, 17366, 43103, 54281, 29112,  6513, 25508, 26526,\n",
      "        28418, 44987, 17544, 47414,  4969, 18366, 41765, 50853, 54849, 49376,\n",
      "        42447,  8766, 54366,   130, 37886, 54704, 39325, 36609,  9800, 54914,\n",
      "        33407, 31230,  9932, 27482,  1718, 17504, 24574,  7640, 34893,  9646],\n",
      "       dtype=torch.int32)\n",
      "isin same block: False\n",
      "CPU times: total: 328 ms\n",
      "Wall time: 63.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "qp = torch.from_numpy(mnist[0])\n",
    "# print(qp)\n",
    "pred = idx.query(qp, k=100)\n",
    "print(f\"recall: {recall(pred, FLAT_I)}\")\n",
    "\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")\n",
    "\n",
    "print(f\"isin same block: {idx.isin(qp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.95\n",
      "pred: tensor([    0, 32248,  8728, 18932, 30483, 24149, 42338, 52295, 26251, 50173,\n",
      "        53634, 24330, 54159, 57528,  1482, 53428, 18123, 31379, 52864, 10536,\n",
      "        36087, 30489, 23947, 20034, 52057, 33825, 21654, 31008, 55208, 22477,\n",
      "        44282, 47968, 54203, 19825,  1634, 27378, 33909, 15378, 24708, 34474,\n",
      "        26413, 16017, 46824, 46358,  1516, 34557, 21629, 29021, 10740, 24107,\n",
      "         5688, 52665,  1864,  5036, 39031,  1978, 40546, 22322, 52231, 37284,\n",
      "         5970, 21976, 16945, 36697, 25675, 54189, 11396, 42555, 33445, 52540,\n",
      "        44263, 18404, 24232, 54184, 25762, 14736, 33970,  5210, 59212,  8642,\n",
      "        22569, 15052,  2933,  6772, 22963,  6516,   832, 21244, 21583, 35838,\n",
      "        59846, 21210, 13502, 52559, 13862, 18172, 41980, 43997, 53812, 18162],\n",
      "       dtype=torch.int32)\n",
      "CPU times: total: 641 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = idx.query_with_threshold(qp, k=100, threshold=0.02, g_block_range=10)\n",
    "print(f\"recall: {recall(pred, FLAT_I)}\")\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "indices = np.random.choice(mnist.shape[0], size=1000, replace=False)\n",
    "\n",
    "def benchmark_knn_query(data, indices, index, k=100):\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "    isin_count = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100, g_block_range=7, l_block_range=4)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "        # isin_count += 1 if index.isin(q) else 0\n",
    "        \n",
    "    result.append((query_time/1000, cur_recall/1000, isin_count/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0794475429058075, 0.9228800000000033, 0.0)]\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "# recall(pred, FLAT_I)\n",
    "\n",
    "benchmark_knn_query(mnist, indices, idx, k=100)\n",
    "print(result)\n",
    "print(idx.get_search_blocks_num())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def benchmark_knn_query_with_threshold(data, indices, index, k=100):\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "    isin_count = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query_with_threshold(q, k=100, threshold=0.05, g_block_range=12)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "        # isin_count += 1 if index.isin(q) else 0\n",
    "        \n",
    "    result.append((query_time/1000, cur_recall/1000, isin_count/1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.060861944675445555, 0.8917400000000021, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "benchmark_knn_query_with_threshold(mnist, indices, idx, k=100)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
