{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist data shape: (60000, 784)\n",
      "mnist dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./Bspli/\")\n",
    "import os  \n",
    "import faiss\n",
    "import time\n",
    "import numpy as np \n",
    "import index \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "mnist = np.load(\"dataset/mnist-784-euclidean.npy\")\n",
    "print(f'mnist data shape: {mnist.shape}')\n",
    "print(f'mnist dtype: {mnist.dtype}')\n",
    "\n",
    "# mnist = np.random.uniform(low=0, high=255, size=(100000, 2))\n",
    "# mnist = mnist.astype(np.float32)\n",
    "# print(f'mnist dtype: {mnist.dtype}')\n",
    "# print(f'mnist data shape: {mnist.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute query: [[    0 32248  8728 18932 30483 24149 42338 52295 26251 50173 53634 24330\n",
      "  54159 57528  1482 53428 18123 31379 52864 10536 29719 36087 30489 23947\n",
      "  20034 52057 33825 21654 31008 55208 22477 44282 47968 54203 19825  1634\n",
      "  27378 33909 15378 24708 34474 26413 16017 46824 46358  1516 34557 16832\n",
      "  21629 29021 10740 24107  5688 52665  1864  5036 39031  1978 40546 22322\n",
      "  52231 37284 24730  5970 21976 16945  9568 36697 25675 54189 11396 42555\n",
      "  33445 52540 44263 18404 19186 24232 54184 25762 14736 33970  5210 59212\n",
      "   8642 22569 15052  2933  6772 22963  6516   832 21244 21583 35838 59846\n",
      "  21210 13502 52559 13862]]\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 71.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Brute Search\n",
    "flat = faiss.IndexFlatL2(mnist.shape[1])\n",
    "flat.add(mnist)\n",
    "\n",
    "D, FLAT_I = flat.search(mnist[0].reshape(1, mnist.shape[1]), k=100) \n",
    "print(f'brute query: {FLAT_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist tensor shape: torch.Size([60000, 784])\n",
      "torch.Size([1995, 785])\n",
      "torch.Size([8906, 785])\n",
      "torch.Size([4610, 785])\n",
      "torch.Size([3738, 785])\n",
      "torch.Size([7329, 785])\n",
      "torch.Size([4915, 785])\n",
      "torch.Size([8447, 785])\n",
      "torch.Size([4660, 785])\n",
      "torch.Size([2740, 785])\n",
      "torch.Size([2620, 785])\n",
      "torch.Size([382, 785])\n",
      "torch.Size([9658, 785])\n",
      "first stage partitioning finish\n",
      "partitioning blocks : 12\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "training local model\n",
      "trainging global model\n",
      "global index train smaple count: 132\n",
      "finish\n",
      "local model len:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\bspli\\./Bspli\\utils\\Partitioning.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ma = torch.tensor(means)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    }
   ],
   "source": [
    "mnist_tensor = torch.from_numpy(mnist)\n",
    "print(f'mnist tensor shape: {mnist_tensor.shape}')\n",
    "\n",
    "idx = index.Indexing(\n",
    "    gl_size=10000, \n",
    "    ll_size=2000,\n",
    "    g_epoch_num=3,\n",
    "    l_epoch_num=10,\n",
    "    g_hidden_size=5,\n",
    "    l_hidden_size=5,\n",
    "    g_block_range=4,\n",
    "    l_block_range=4,\n",
    "    random_partitioning=False\n",
    ")\n",
    "idx.train(mnist_tensor)\n",
    "\n",
    "print(f\"local model len:{len(idx._l_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.73\n",
      "pred: tensor([    0,  8728, 30483, 24149, 42338, 52295, 50173, 53634, 24330,  1482,\n",
      "        53428, 18123, 31379, 52864, 10536, 36087, 30489, 23947, 20034, 52057,\n",
      "        21654, 44282, 54203, 19825,  1634, 27378, 33909, 15378, 24708,  1516,\n",
      "        34557, 29021, 10740, 24107,  5688, 52665,  1864,  5036, 39031,  1978,\n",
      "        40546, 22322,  5970, 21976, 16945, 36697, 25675, 54189, 11396, 42555,\n",
      "        33445, 52540, 44263, 24232, 54184, 25762, 14736, 33970,  5210, 59212,\n",
      "         8642, 22569, 15052,  2933, 22963,  6516,   832, 21244, 35838, 21210,\n",
      "        13502, 52559, 13862, 41980, 43997, 53812, 13193, 46698, 15975, 46968,\n",
      "        50187,  3188, 28384, 24271, 21661, 15907, 33469, 38896, 15444, 23225,\n",
      "        29049, 50071, 45567, 43031, 26313,  2395, 11936, 16112, 49334, 44476],\n",
      "       dtype=torch.int32)\n",
      "CPU times: total: 453 ms\n",
      "Wall time: 82.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "qp = torch.from_numpy(mnist[0])\n",
    "# print(qp)\n",
    "pred = idx.query(qp, k=100)\n",
    "print(f\"recall: {recall(pred, FLAT_I)}\")\n",
    "\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def benchmark_knn_query(data, index, size=1000, k=100):\n",
    "    indices = np.random.choice(data.shape[0], size, replace=False)\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100, g_block_range=8, l_block_range=5)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "    result.append((query_time/1000, cur_recall/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall(pred, FLAT_I)\n",
    "\n",
    "benchmark_knn_query(mnist, idx, size=1000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.10986903166770935, 0.9176100000000027)]\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(idx.get_search_blocks_num())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.55 s\n",
      "Wall time: 2.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "tree = BallTree(mnist, leaf_size=2000)\n",
    "dist, ind = tree.query(mnist[0].reshape(1, mnist.shape[1]), k=100) \n",
    "\n",
    "flat = faiss.IndexFlatL2(mnist.shape[1])\n",
    "flat.add(mnist)\n",
    "\n",
    "D, FLAT_I = flat.search(mnist[0].reshape(1, mnist.shape[1]), k=100) \n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "\n",
    "def benchmark_knn_query(data, index, size=1000, k=100):\n",
    "    indices = np.random.choice(data.shape[0], size, replace=False)\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = data[i].reshape(1, mnist.shape[1])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "    result.append((query_time/1000, cur_recall/1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
