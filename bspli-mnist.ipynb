{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist data shape: (60000, 784)\n",
      "brute query: [[    0 32248  8728 18932 30483 24149 42338 52295 26251 50173 53634 24330\n",
      "  54159 57528  1482 53428 18123 31379 52864 10536 29719 36087 30489 23947\n",
      "  20034 52057 33825 21654 31008 55208 22477 44282 47968 54203 19825  1634\n",
      "  27378 33909 15378 24708 34474 26413 16017 46824 46358  1516 34557 16832\n",
      "  21629 29021 10740 24107  5688 52665  1864  5036 39031  1978 40546 22322\n",
      "  52231 37284 24730  5970 21976 16945  9568 36697 25675 54189 11396 42555\n",
      "  33445 52540 44263 18404 19186 24232 54184 25762 14736 33970  5210 59212\n",
      "   8642 22569 15052  2933  6772 22963  6516   832 21244 21583 35838 59846\n",
      "  21210 13502 52559 13862]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./Bspli/\")\n",
    "import os  \n",
    "import faiss\n",
    "import time\n",
    "import numpy as np \n",
    "import index \n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "mnist = np.load(\"dataset/mnist-784-euclidean.npy\")\n",
    "print(f'mnist data shape: {mnist.shape}')\n",
    "\n",
    "flat = faiss.IndexFlatL2(mnist.shape[1])\n",
    "flat.add(mnist)\n",
    "\n",
    "D, FLAT_I = flat.search(mnist[0].reshape(1, mnist.shape[1]), k=100) \n",
    "print(f'brute query: {FLAT_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist tensor shape: torch.Size([60000, 784])\n",
      "torch.Size([1995, 785])\n",
      "torch.Size([8906, 785])\n",
      "torch.Size([4610, 785])\n",
      "torch.Size([3738, 785])\n",
      "torch.Size([7329, 785])\n",
      "torch.Size([4915, 785])\n",
      "torch.Size([8447, 785])\n",
      "torch.Size([4660, 785])\n",
      "torch.Size([2740, 785])\n",
      "torch.Size([2620, 785])\n",
      "torch.Size([382, 785])\n",
      "torch.Size([9658, 785])\n",
      "first stage partitioning finish\n",
      "partitioning blocks : 12\n",
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([95])) that is different to the input size (torch.Size([95, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([6, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([38])) that is different to the input size (torch.Size([38, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([29])) that is different to the input size (torch.Size([29, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([47])) that is different to the input size (torch.Size([47, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([60])) that is different to the input size (torch.Size([60, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([40])) that is different to the input size (torch.Size([40, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training local model\n",
      "training local model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([82])) that is different to the input size (torch.Size([82, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([58])) that is different to the input size (torch.Size([58, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainging global model\n",
      "global index train smaple count: 1136\n",
      "1, 100 loss: 0.22270217895507813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\bspli\\./Bspli\\utils\\Partitioning.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ma = torch.tensor(means)\n",
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 200 loss: 0.0730033826828003\n",
      "2, 100 loss: 0.027911345958709716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:928: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 200 loss: 0.0752277421951294\n",
      "3, 100 loss: 0.03239293098449707\n",
      "3, 200 loss: 0.014987295866012574\n",
      "4, 100 loss: 0.04135410785675049\n",
      "4, 200 loss: 0.04425270557403564\n",
      "5, 100 loss: 0.03342489004135132\n",
      "5, 200 loss: 0.026667275428771973\n",
      "6, 100 loss: 0.02080756187438965\n",
      "6, 200 loss: 0.03726217031478882\n",
      "7, 100 loss: 0.030130791664123534\n",
      "7, 200 loss: 0.03246382236480713\n",
      "8, 100 loss: 0.03450248718261719\n",
      "8, 200 loss: 0.028401031494140624\n",
      "9, 100 loss: 0.040837492942810055\n",
      "9, 200 loss: 0.01879252791404724\n",
      "10, 100 loss: 0.22167373657226563\n",
      "10, 200 loss: 0.03586964130401611\n",
      "finish\n",
      "local model len:12\n"
     ]
    }
   ],
   "source": [
    "mnist_tensor = torch.from_numpy(mnist)\n",
    "print(f'mnist tensor shape: {mnist_tensor.shape}')\n",
    "\n",
    "index = index.Indexing(gl_size=10000, ll_size=100, random_partitioning=False)\n",
    "index.train(mnist_tensor)\n",
    "\n",
    "print(f\"local model len:{len(index._l_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "pred: tensor([24435, 14223, 48533,  1201, 16530,  6111, 26066,  1315, 35764, 46965,\n",
      "         5531, 29306, 59473,  6251, 29279, 33664, 28065, 39489, 12223, 22268,\n",
      "        43754, 17244, 20751, 15246, 35038, 36579,  6367, 44458,  1997, 23562,\n",
      "        29493, 11661,  5938, 19237, 15458,  9852,  2598, 25357,  6409, 54636,\n",
      "        28485,  6341, 28760,  7238, 12633, 14173, 50765, 21785,  8223, 29192,\n",
      "        35736, 12580, 19485,  6357, 53946, 11027, 16220, 23063,  5399, 41883,\n",
      "        13336, 11492, 36623, 31474, 27958,  6071,  1349, 15516, 23971, 54689,\n",
      "        48161, 42681,  6891, 25252, 51646, 19769, 53903, 17454, 36677,  5977,\n",
      "        22453, 36599, 23809, 21825, 38297, 33003, 22767, 50036,  6768,  6017,\n",
      "        32274,  8897,  6093, 23125, 48139, 24075, 25840, 19213,  8896, 28365],\n",
      "       dtype=torch.int32)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 8.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qp = torch.from_numpy(mnist[0])\n",
    "# print(qp)\n",
    "pred = index.query(qp, k=100)\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "\n",
    "def benchmark_knn_query(data, index, size=1000, k=100):\n",
    "    indices = np.random.choice(data.shape[0], size, replace=False)\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "    result.append((query_time/1000, cur_recall/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global max block num: 12.0\n",
      "predicted local model: 3\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 0\n",
      "The global max block num: 12.0\n",
      "predicted local model: 1\n",
      "The global max block num: 12.0\n",
      "predicted local model: 12\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# recall(pred, FLAT_I)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m benchmark_knn_query(mnist, index, size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, k\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mbenchmark_knn_query\u001b[1;34m(data, index, size, k)\u001b[0m\n\u001b[0;32m     15\u001b[0m q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(data[i])\n\u001b[0;32m     16\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 17\u001b[0m qk \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mquery(q, k\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m query_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start)\n\u001b[0;32m     19\u001b[0m D, FLAT_I \u001b[39m=\u001b[39m flat\u001b[39m.\u001b[39msearch(data[i]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), k\u001b[39m=\u001b[39mk) \n",
      "File \u001b[1;32md:\\study\\bspli\\./Bspli\\index.py:84\u001b[0m, in \u001b[0;36mIndexing.query\u001b[1;34m(self, qp, k)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredicted local model: \u001b[39m\u001b[39m{\u001b[39;00mpred\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[39m# get the topk result indices\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_l_model[pred]\u001b[39m.\u001b[39mquery(qp, k)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# recall(pred, FLAT_I)\n",
    "\n",
    "benchmark_knn_query(mnist, index, size=1000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.007357717037200928, 0.019600000000000006), (0.25210712623596193, 0.972840000000001)]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
