{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift data shape: (1000000, 128)\n",
      "brute query: [[     0      2      6  83606 631203 677834 246710 677793 480592  10336\n",
      "  658180 799350 738996 516942 965310 451321 725637 480903 719046 248230\n",
      "  799488 500141 799404 466880 529593 688749 558961 686828 183625 432221\n",
      "  532473 187896 678008 772144  89757 432521 182418 633385 596413 657774\n",
      "  679499 769701 930778 236210 528709 216605 738730 192507 271323 559065\n",
      "  134358  81704 631964 206873 271151 851764 261934 225014 404206 632106\n",
      "  256176 547359 514307 523094 630017 258188 705267 216395 419350 204933\n",
      "  269211 197644 276460  65965 551986 876717 228378  95134  87235 719140\n",
      "  407157  79225 808018 559250 420871 525531 162637 764500 547845 724103\n",
      "  547004 219183 832018 533417  42705 197990 276806 720756 116581 729207]]\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import faiss\n",
    "import time\n",
    "import numpy as np \n",
    "import bspli\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "sift = np.load(\"dataset/sift-128-euclidean.npy\")\n",
    "print(f'sift data shape: {sift.shape}')\n",
    "\n",
    "flat = faiss.IndexFlatL2(sift.shape[1])\n",
    "flat.add(sift)\n",
    "\n",
    "D, FLAT_I = flat.search(sift[0].reshape(1, sift.shape[1]), k=100) \n",
    "print(f'brute query: {FLAT_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift tensor shape: torch.Size([1000000, 128])\n",
      "torch.Size([343802, 129])\n",
      "torch.Size([656198, 129])\n",
      "first stage partitioning finish\n",
      "partitioning blocks : 2\n",
      "training local model\n",
      "1, 100 loss: 0.07621049404144287\n",
      "1, 200 loss: 0.07621051788330079\n",
      "1, 300 loss: 0.07621056556701661\n",
      "1, 400 loss: 0.07621056556701661\n",
      "1, 500 loss: 0.07621056556701661\n",
      "1, 600 loss: 0.07621056556701661\n",
      "1, 700 loss: 0.07621056556701661\n",
      "1, 800 loss: 0.07621056556701661\n",
      "1, 900 loss: 0.07621054172515869\n",
      "1, 1000 loss: 0.07621056556701661\n",
      "1, 1100 loss: 0.07621056556701661\n",
      "1, 1200 loss: 0.07621056556701661\n",
      "1, 1300 loss: 0.07621056556701661\n",
      "1, 1400 loss: 0.07621056556701661\n",
      "1, 1500 loss: 0.07621056556701661\n",
      "1, 1600 loss: 0.07621056556701661\n",
      "1, 1700 loss: 0.07621056556701661\n",
      "1, 1800 loss: 0.07611056327819825\n",
      "1, 1900 loss: 0.07621056079864502\n",
      "1, 2000 loss: 0.07621056079864502\n",
      "1, 2100 loss: 0.07621054649353028\n",
      "1, 2200 loss: 0.07621056079864502\n",
      "1, 2300 loss: 0.07621055126190185\n",
      "1, 2400 loss: 0.07621054649353028\n",
      "1, 2500 loss: 0.07621056556701661\n",
      "1, 2600 loss: 0.07621054172515869\n",
      "1, 2700 loss: 0.07621056556701661\n",
      "1, 2800 loss: 0.07621056556701661\n",
      "1, 2900 loss: 0.07621056556701661\n",
      "1, 3000 loss: 0.07621056556701661\n",
      "1, 3100 loss: 0.07621056079864502\n",
      "1, 3200 loss: 0.07611056327819825\n",
      "1, 3300 loss: 0.07621056556701661\n",
      "1, 3400 loss: 0.07621056556701661\n",
      "2, 100 loss: 0.07621056556701661\n",
      "2, 200 loss: 0.07621056079864502\n",
      "2, 300 loss: 0.07601056575775146\n",
      "2, 400 loss: 0.07621056556701661\n",
      "2, 500 loss: 0.07621056556701661\n",
      "2, 600 loss: 0.07621056556701661\n",
      "2, 700 loss: 0.07611056327819825\n",
      "2, 800 loss: 0.07611053466796874\n",
      "2, 900 loss: 0.07621056556701661\n",
      "2, 1000 loss: 0.07621056556701661\n",
      "2, 1100 loss: 0.07621055126190185\n",
      "2, 1200 loss: 0.07611056327819825\n",
      "2, 1300 loss: 0.07621055126190185\n",
      "2, 1400 loss: 0.07621056556701661\n",
      "2, 1500 loss: 0.07621056079864502\n",
      "2, 1600 loss: 0.07611053466796874\n",
      "2, 1700 loss: 0.07621054649353028\n",
      "2, 1800 loss: 0.07621056556701661\n",
      "2, 1900 loss: 0.07621055126190185\n",
      "2, 2000 loss: 0.07621054172515869\n",
      "2, 2100 loss: 0.07611050605773925\n",
      "2, 2200 loss: 0.0762105369567871\n",
      "2, 2300 loss: 0.07621056556701661\n",
      "2, 2400 loss: 0.07621056079864502\n",
      "2, 2500 loss: 0.07621056556701661\n",
      "2, 2600 loss: 0.07621055126190185\n",
      "2, 2700 loss: 0.07621052742004394\n",
      "2, 2800 loss: 0.07621054172515869\n",
      "2, 2900 loss: 0.07621056556701661\n",
      "2, 3000 loss: 0.07621056556701661\n",
      "2, 3100 loss: 0.07621056556701661\n",
      "2, 3200 loss: 0.07621056556701661\n",
      "2, 3300 loss: 0.07621054649353028\n",
      "2, 3400 loss: 0.07621054649353028\n",
      "3, 100 loss: 0.07621054172515869\n",
      "3, 200 loss: 0.07621056556701661\n",
      "3, 300 loss: 0.07621056556701661\n",
      "3, 400 loss: 0.07621056556701661\n",
      "3, 500 loss: 0.0762105369567871\n",
      "3, 600 loss: 0.07621056556701661\n",
      "3, 700 loss: 0.07621055126190185\n",
      "3, 800 loss: 0.07621054172515869\n",
      "3, 900 loss: 0.07621056556701661\n",
      "3, 1000 loss: 0.07621052265167236\n",
      "3, 1100 loss: 0.07621056556701661\n",
      "3, 1200 loss: 0.07621056556701661\n",
      "3, 1300 loss: 0.07621056556701661\n",
      "3, 1400 loss: 0.07621056556701661\n",
      "3, 1500 loss: 0.07611056327819825\n",
      "3, 1600 loss: 0.07621052265167236\n",
      "3, 1700 loss: 0.07621056556701661\n",
      "3, 1800 loss: 0.07621056556701661\n",
      "3, 1900 loss: 0.07621056079864502\n",
      "3, 2000 loss: 0.07621051788330079\n",
      "3, 2100 loss: 0.07621054172515869\n",
      "3, 2200 loss: 0.07621055126190185\n",
      "3, 2300 loss: 0.07621050834655761\n",
      "3, 2400 loss: 0.07621054172515869\n",
      "3, 2500 loss: 0.07621055126190185\n",
      "3, 2600 loss: 0.07621056079864502\n",
      "3, 2700 loss: 0.07621054172515869\n",
      "3, 2800 loss: 0.07621055126190185\n",
      "3, 2900 loss: 0.07621054172515869\n",
      "3, 3000 loss: 0.07621054172515869\n",
      "3, 3100 loss: 0.07621048450469971\n",
      "3, 3200 loss: 0.07621052265167236\n",
      "3, 3300 loss: 0.07621054172515869\n",
      "3, 3400 loss: 0.0761105489730835\n",
      "4, 100 loss: 0.07621056556701661\n",
      "4, 200 loss: 0.07621054649353028\n",
      "4, 300 loss: 0.07621055126190185\n",
      "4, 400 loss: 0.0762105369567871\n",
      "4, 500 loss: 0.07621055126190185\n",
      "4, 600 loss: 0.07621054172515869\n",
      "4, 700 loss: 0.07621049880981445\n",
      "4, 800 loss: 0.07621052742004394\n",
      "4, 900 loss: 0.07611048698425293\n",
      "4, 1000 loss: 0.07621050834655761\n",
      "4, 1100 loss: 0.07621050357818604\n",
      "4, 1200 loss: 0.07611051082611084\n",
      "4, 1300 loss: 0.07621054649353028\n",
      "4, 1400 loss: 0.07621050834655761\n",
      "4, 1500 loss: 0.07621045589447022\n",
      "4, 1600 loss: 0.07611051082611084\n",
      "4, 1700 loss: 0.0762104606628418\n",
      "4, 1800 loss: 0.07621046543121338\n",
      "4, 1900 loss: 0.07621054172515869\n",
      "4, 2000 loss: 0.07621047973632812\n",
      "4, 2100 loss: 0.07621049404144287\n",
      "4, 2200 loss: 0.07621055126190185\n",
      "4, 2300 loss: 0.07621052265167236\n",
      "4, 2400 loss: 0.07621056556701661\n",
      "4, 2500 loss: 0.07621054649353028\n",
      "4, 2600 loss: 0.07621054649353028\n",
      "4, 2700 loss: 0.07621056079864502\n",
      "4, 2800 loss: 0.07621055126190185\n",
      "4, 2900 loss: 0.07621052265167236\n",
      "4, 3000 loss: 0.07611052989959717\n",
      "4, 3100 loss: 0.07621054172515869\n",
      "4, 3200 loss: 0.07611055374145508\n",
      "4, 3300 loss: 0.07621054172515869\n",
      "4, 3400 loss: 0.07621055126190185\n",
      "5, 100 loss: 0.07621054649353028\n",
      "5, 200 loss: 0.07621054649353028\n",
      "5, 300 loss: 0.07621056079864502\n",
      "5, 400 loss: 0.07621054649353028\n",
      "5, 500 loss: 0.07621049880981445\n",
      "5, 600 loss: 0.07621050834655761\n",
      "5, 700 loss: 0.07621050834655761\n",
      "5, 800 loss: 0.07621051788330079\n",
      "5, 900 loss: 0.07621056556701661\n",
      "5, 1000 loss: 0.07621054649353028\n",
      "5, 1100 loss: 0.07621054172515869\n",
      "5, 1200 loss: 0.07621054649353028\n",
      "5, 1300 loss: 0.07621056079864502\n",
      "5, 1400 loss: 0.07611056327819825\n",
      "5, 1500 loss: 0.07611051559448243\n",
      "5, 1600 loss: 0.07621055126190185\n",
      "5, 1700 loss: 0.07621056079864502\n",
      "5, 1800 loss: 0.07621052265167236\n",
      "5, 1900 loss: 0.07621054172515869\n",
      "5, 2000 loss: 0.07621051788330079\n",
      "5, 2100 loss: 0.07621052742004394\n",
      "5, 2200 loss: 0.07621052742004394\n",
      "5, 2300 loss: 0.07621054172515869\n",
      "5, 2400 loss: 0.07621056556701661\n",
      "5, 2500 loss: 0.0762105369567871\n",
      "5, 2600 loss: 0.0762105369567871\n",
      "5, 2700 loss: 0.07621050357818604\n",
      "5, 2800 loss: 0.07621050834655761\n",
      "5, 2900 loss: 0.07621054649353028\n",
      "5, 3000 loss: 0.07621052265167236\n",
      "5, 3100 loss: 0.07621054172515869\n",
      "5, 3200 loss: 0.07621055126190185\n",
      "5, 3300 loss: 0.07621052742004394\n",
      "5, 3400 loss: 0.07621052265167236\n",
      "training local model\n",
      "1, 100 loss: 0.08269682884216309\n",
      "1, 200 loss: 0.08269682884216309\n",
      "1, 300 loss: 0.08269682884216309\n",
      "1, 400 loss: 0.08269682884216309\n",
      "1, 500 loss: 0.08269682884216309\n",
      "1, 600 loss: 0.08269682884216309\n",
      "1, 700 loss: 0.08269682884216309\n",
      "1, 800 loss: 0.08269682884216309\n",
      "1, 900 loss: 0.08269682884216309\n",
      "1, 1000 loss: 0.08269682884216309\n",
      "1, 1100 loss: 0.08269682884216309\n",
      "1, 1200 loss: 0.08269682884216309\n",
      "1, 1300 loss: 0.08269682884216309\n",
      "1, 1400 loss: 0.08269681930541992\n",
      "1, 1500 loss: 0.0826968002319336\n",
      "1, 1600 loss: 0.08269681930541992\n",
      "1, 1700 loss: 0.08269680976867676\n",
      "1, 1800 loss: 0.0826968002319336\n",
      "1, 1900 loss: 0.08269674301147462\n",
      "1, 2000 loss: 0.08269678115844727\n",
      "1, 2100 loss: 0.08269682884216309\n",
      "1, 2200 loss: 0.08269682884216309\n",
      "1, 2300 loss: 0.08269682884216309\n",
      "1, 2400 loss: 0.08269682884216309\n",
      "1, 2500 loss: 0.08269682884216309\n",
      "1, 2600 loss: 0.08269682884216309\n",
      "1, 2700 loss: 0.08269682884216309\n",
      "1, 2800 loss: 0.08259682655334473\n",
      "1, 2900 loss: 0.08269682884216309\n",
      "1, 3000 loss: 0.08269682884216309\n",
      "1, 3100 loss: 0.08269682884216309\n",
      "1, 3200 loss: 0.08269682884216309\n",
      "1, 3300 loss: 0.08259682655334473\n",
      "1, 3400 loss: 0.08269682884216309\n",
      "1, 3500 loss: 0.08269682884216309\n",
      "1, 3600 loss: 0.08259682655334473\n",
      "1, 3700 loss: 0.08269682884216309\n",
      "1, 3800 loss: 0.08269682884216309\n",
      "1, 3900 loss: 0.08269682884216309\n",
      "1, 4000 loss: 0.08259682655334473\n",
      "1, 4100 loss: 0.08269682884216309\n",
      "1, 4200 loss: 0.08269682884216309\n",
      "1, 4300 loss: 0.08269682884216309\n",
      "1, 4400 loss: 0.08269682884216309\n",
      "1, 4500 loss: 0.08269682884216309\n",
      "1, 4600 loss: 0.08269682884216309\n",
      "1, 4700 loss: 0.08269682884216309\n",
      "1, 4800 loss: 0.08259682655334473\n",
      "1, 4900 loss: 0.08269682884216309\n",
      "1, 5000 loss: 0.08269682884216309\n",
      "1, 5100 loss: 0.08269682884216309\n",
      "1, 5200 loss: 0.08269682884216309\n",
      "1, 5300 loss: 0.08269682884216309\n",
      "1, 5400 loss: 0.08269682884216309\n",
      "1, 5500 loss: 0.08269682884216309\n",
      "1, 5600 loss: 0.08269682884216309\n",
      "1, 5700 loss: 0.08269682884216309\n",
      "1, 5800 loss: 0.08269682884216309\n",
      "1, 5900 loss: 0.08269682884216309\n",
      "1, 6000 loss: 0.08269682884216309\n",
      "1, 6100 loss: 0.08269682884216309\n",
      "1, 6200 loss: 0.08259682655334473\n",
      "1, 6300 loss: 0.08269682884216309\n",
      "1, 6400 loss: 0.08269682884216309\n",
      "1, 6500 loss: 0.08269682884216309\n",
      "2, 100 loss: 0.08269682884216309\n",
      "2, 200 loss: 0.08269681930541992\n",
      "2, 300 loss: 0.08269682884216309\n",
      "2, 400 loss: 0.08269682884216309\n",
      "2, 500 loss: 0.08269682884216309\n",
      "2, 600 loss: 0.08269682884216309\n",
      "2, 700 loss: 0.08269682884216309\n",
      "2, 800 loss: 0.08269682884216309\n",
      "2, 900 loss: 0.08269682884216309\n",
      "2, 1000 loss: 0.08269682884216309\n",
      "2, 1100 loss: 0.08269682884216309\n",
      "2, 1200 loss: 0.08269682884216309\n",
      "2, 1300 loss: 0.08269682884216309\n",
      "2, 1400 loss: 0.08269682884216309\n",
      "2, 1500 loss: 0.08269682884216309\n",
      "2, 1600 loss: 0.08269682884216309\n",
      "2, 1700 loss: 0.08269682884216309\n",
      "2, 1800 loss: 0.08269682884216309\n",
      "2, 1900 loss: 0.08269682884216309\n",
      "2, 2000 loss: 0.08269682884216309\n",
      "2, 2100 loss: 0.08259682655334473\n",
      "2, 2200 loss: 0.08259682655334473\n",
      "2, 2300 loss: 0.08259682655334473\n",
      "2, 2400 loss: 0.08269682884216309\n",
      "2, 2500 loss: 0.08269682884216309\n",
      "2, 2600 loss: 0.08269682884216309\n",
      "2, 2700 loss: 0.08269682884216309\n",
      "2, 2800 loss: 0.08269682884216309\n",
      "2, 2900 loss: 0.08269682884216309\n",
      "2, 3000 loss: 0.08259682655334473\n",
      "2, 3100 loss: 0.08269682884216309\n",
      "2, 3200 loss: 0.08269682884216309\n",
      "2, 3300 loss: 0.08269682884216309\n",
      "2, 3400 loss: 0.08269682884216309\n",
      "2, 3500 loss: 0.08269682884216309\n",
      "2, 3600 loss: 0.08269682884216309\n",
      "2, 3700 loss: 0.08269682884216309\n",
      "2, 3800 loss: 0.08269682884216309\n",
      "2, 3900 loss: 0.08269682884216309\n",
      "2, 4000 loss: 0.08259682655334473\n",
      "2, 4100 loss: 0.08269682884216309\n",
      "2, 4200 loss: 0.08269682884216309\n",
      "2, 4300 loss: 0.08269682884216309\n",
      "2, 4400 loss: 0.08269682884216309\n",
      "2, 4500 loss: 0.08269682884216309\n",
      "2, 4600 loss: 0.08269682884216309\n",
      "2, 4700 loss: 0.08269682884216309\n",
      "2, 4800 loss: 0.08269682884216309\n",
      "2, 4900 loss: 0.08269682884216309\n",
      "2, 5000 loss: 0.08269682884216309\n",
      "2, 5100 loss: 0.08269682884216309\n",
      "2, 5200 loss: 0.08269682884216309\n",
      "2, 5300 loss: 0.08269682884216309\n",
      "2, 5400 loss: 0.08269682884216309\n",
      "2, 5500 loss: 0.08269682884216309\n",
      "2, 5600 loss: 0.08269682884216309\n",
      "2, 5700 loss: 0.08259682655334473\n",
      "2, 5800 loss: 0.08269682884216309\n",
      "2, 5900 loss: 0.08269682884216309\n",
      "2, 6000 loss: 0.08269682884216309\n",
      "2, 6100 loss: 0.08269682884216309\n",
      "2, 6200 loss: 0.08269682884216309\n",
      "2, 6300 loss: 0.08259682655334473\n",
      "2, 6400 loss: 0.08269682884216309\n",
      "2, 6500 loss: 0.08269682884216309\n",
      "3, 100 loss: 0.08269682884216309\n",
      "3, 200 loss: 0.08269682884216309\n",
      "3, 300 loss: 0.08269682884216309\n",
      "3, 400 loss: 0.08269682884216309\n",
      "3, 500 loss: 0.08269682884216309\n",
      "3, 600 loss: 0.08269682884216309\n",
      "3, 700 loss: 0.08269682884216309\n",
      "3, 800 loss: 0.08269682884216309\n",
      "3, 900 loss: 0.08269682884216309\n",
      "3, 1000 loss: 0.08269682884216309\n",
      "3, 1100 loss: 0.08269682884216309\n",
      "3, 1200 loss: 0.08269682884216309\n",
      "3, 1300 loss: 0.08269682884216309\n",
      "3, 1400 loss: 0.08269682884216309\n",
      "3, 1500 loss: 0.08269682884216309\n",
      "3, 1600 loss: 0.08269682884216309\n",
      "3, 1700 loss: 0.08269682884216309\n",
      "3, 1800 loss: 0.08269682884216309\n",
      "3, 1900 loss: 0.08259682655334473\n",
      "3, 2000 loss: 0.08269682884216309\n",
      "3, 2100 loss: 0.08269682884216309\n",
      "3, 2200 loss: 0.08269682884216309\n",
      "3, 2300 loss: 0.08259682655334473\n",
      "3, 2400 loss: 0.08269682884216309\n",
      "3, 2500 loss: 0.08269682884216309\n",
      "3, 2600 loss: 0.08269682884216309\n",
      "3, 2700 loss: 0.08269682884216309\n",
      "3, 2800 loss: 0.08269682884216309\n",
      "3, 2900 loss: 0.08269682884216309\n",
      "3, 3000 loss: 0.08269682884216309\n",
      "3, 3100 loss: 0.08269682884216309\n",
      "3, 3200 loss: 0.08269682884216309\n",
      "3, 3300 loss: 0.08269682884216309\n",
      "3, 3400 loss: 0.08269682884216309\n",
      "3, 3500 loss: 0.08259682655334473\n",
      "3, 3600 loss: 0.08269682884216309\n",
      "3, 3700 loss: 0.08269682884216309\n",
      "3, 3800 loss: 0.08269680976867676\n",
      "3, 3900 loss: 0.08269682884216309\n",
      "3, 4000 loss: 0.08269682884216309\n",
      "3, 4100 loss: 0.08269682884216309\n",
      "3, 4200 loss: 0.08269682884216309\n",
      "3, 4300 loss: 0.08269682884216309\n",
      "3, 4400 loss: 0.08269682884216309\n",
      "3, 4500 loss: 0.08269682884216309\n",
      "3, 4600 loss: 0.08269682884216309\n",
      "3, 4700 loss: 0.08269682884216309\n",
      "3, 4800 loss: 0.08269682884216309\n",
      "3, 4900 loss: 0.08269682884216309\n",
      "3, 5000 loss: 0.08269682884216309\n",
      "3, 5100 loss: 0.08269682884216309\n",
      "3, 5200 loss: 0.08259682655334473\n",
      "3, 5300 loss: 0.08269682884216309\n",
      "3, 5400 loss: 0.08269682884216309\n",
      "3, 5500 loss: 0.08269682884216309\n",
      "3, 5600 loss: 0.08269682884216309\n",
      "3, 5700 loss: 0.08269682884216309\n",
      "3, 5800 loss: 0.08269682884216309\n",
      "3, 5900 loss: 0.08269682884216309\n",
      "3, 6000 loss: 0.08269682884216309\n",
      "3, 6100 loss: 0.08269682884216309\n",
      "3, 6200 loss: 0.08259682655334473\n",
      "3, 6300 loss: 0.08269682884216309\n",
      "3, 6400 loss: 0.08269682884216309\n",
      "3, 6500 loss: 0.08269682884216309\n",
      "4, 100 loss: 0.08269682884216309\n",
      "4, 200 loss: 0.08269682884216309\n",
      "4, 300 loss: 0.08269682884216309\n",
      "4, 400 loss: 0.08269682884216309\n",
      "4, 500 loss: 0.08269682884216309\n",
      "4, 600 loss: 0.08269682884216309\n",
      "4, 700 loss: 0.08269682884216309\n",
      "4, 800 loss: 0.08269682884216309\n",
      "4, 900 loss: 0.08259682655334473\n",
      "4, 1000 loss: 0.08269682884216309\n",
      "4, 1100 loss: 0.08269682884216309\n",
      "4, 1200 loss: 0.08269682884216309\n",
      "4, 1300 loss: 0.08269682884216309\n",
      "4, 1400 loss: 0.08269682884216309\n",
      "4, 1500 loss: 0.08269682884216309\n",
      "4, 1600 loss: 0.08269682884216309\n",
      "4, 1700 loss: 0.08269682884216309\n",
      "4, 1800 loss: 0.08269682884216309\n",
      "4, 1900 loss: 0.08269682884216309\n",
      "4, 2000 loss: 0.08269682884216309\n",
      "4, 2100 loss: 0.08269682884216309\n",
      "4, 2200 loss: 0.08269682884216309\n",
      "4, 2300 loss: 0.08269682884216309\n",
      "4, 2400 loss: 0.08269682884216309\n",
      "4, 2500 loss: 0.08269682884216309\n",
      "4, 2600 loss: 0.08269682884216309\n",
      "4, 2700 loss: 0.08269682884216309\n",
      "4, 2800 loss: 0.08269682884216309\n",
      "4, 2900 loss: 0.08269682884216309\n",
      "4, 3000 loss: 0.08259682655334473\n",
      "4, 3100 loss: 0.08269682884216309\n",
      "4, 3200 loss: 0.08269682884216309\n",
      "4, 3300 loss: 0.08269682884216309\n",
      "4, 3400 loss: 0.08269682884216309\n",
      "4, 3500 loss: 0.08269682884216309\n",
      "4, 3600 loss: 0.08259682655334473\n",
      "4, 3700 loss: 0.08269682884216309\n",
      "4, 3800 loss: 0.08269682884216309\n",
      "4, 3900 loss: 0.08269682884216309\n",
      "4, 4000 loss: 0.08269682884216309\n",
      "4, 4100 loss: 0.08269682884216309\n",
      "4, 4200 loss: 0.08269682884216309\n",
      "4, 4300 loss: 0.08269682884216309\n",
      "4, 4400 loss: 0.08269682884216309\n",
      "4, 4500 loss: 0.08269682884216309\n",
      "4, 4600 loss: 0.08269682884216309\n",
      "4, 4700 loss: 0.08269682884216309\n",
      "4, 4800 loss: 0.08269682884216309\n",
      "4, 4900 loss: 0.08269682884216309\n",
      "4, 5000 loss: 0.08269682884216309\n",
      "4, 5100 loss: 0.08259682655334473\n",
      "4, 5200 loss: 0.08269682884216309\n",
      "4, 5300 loss: 0.08269682884216309\n",
      "4, 5400 loss: 0.08269682884216309\n",
      "4, 5500 loss: 0.08269682884216309\n",
      "4, 5600 loss: 0.08269682884216309\n",
      "4, 5700 loss: 0.08259682655334473\n",
      "4, 5800 loss: 0.08269682884216309\n",
      "4, 5900 loss: 0.08269682884216309\n",
      "4, 6000 loss: 0.08269682884216309\n",
      "4, 6100 loss: 0.08269682884216309\n",
      "4, 6200 loss: 0.08269682884216309\n",
      "4, 6300 loss: 0.08269682884216309\n",
      "4, 6400 loss: 0.08269682884216309\n",
      "4, 6500 loss: 0.08269682884216309\n",
      "5, 100 loss: 0.08269682884216309\n",
      "5, 200 loss: 0.08269682884216309\n",
      "5, 300 loss: 0.08269682884216309\n",
      "5, 400 loss: 0.08269682884216309\n",
      "5, 500 loss: 0.08269682884216309\n",
      "5, 600 loss: 0.08269682884216309\n",
      "5, 700 loss: 0.08269682884216309\n",
      "5, 800 loss: 0.08269682884216309\n",
      "5, 900 loss: 0.08269682884216309\n",
      "5, 1000 loss: 0.08269682884216309\n",
      "5, 1100 loss: 0.08269682884216309\n",
      "5, 1200 loss: 0.08269682884216309\n",
      "5, 1300 loss: 0.08269682884216309\n",
      "5, 1400 loss: 0.08269681930541992\n",
      "5, 1500 loss: 0.08269682884216309\n",
      "5, 1600 loss: 0.08269682884216309\n",
      "5, 1700 loss: 0.08269682884216309\n",
      "5, 1800 loss: 0.08269682884216309\n",
      "5, 1900 loss: 0.08269682884216309\n",
      "5, 2000 loss: 0.08269682884216309\n",
      "5, 2100 loss: 0.08269682884216309\n",
      "5, 2200 loss: 0.08269682884216309\n",
      "5, 2300 loss: 0.08269681930541992\n",
      "5, 2400 loss: 0.08269682884216309\n",
      "5, 2500 loss: 0.08269682884216309\n",
      "5, 2600 loss: 0.08269682884216309\n",
      "5, 2700 loss: 0.08269682884216309\n",
      "5, 2800 loss: 0.08269682884216309\n",
      "5, 2900 loss: 0.08269682884216309\n",
      "5, 3000 loss: 0.08269682884216309\n",
      "5, 3100 loss: 0.08269682884216309\n",
      "5, 3200 loss: 0.08269682884216309\n",
      "5, 3300 loss: 0.08269681930541992\n",
      "5, 3400 loss: 0.08269682884216309\n",
      "5, 3500 loss: 0.08269682884216309\n",
      "5, 3600 loss: 0.08269682884216309\n",
      "5, 3700 loss: 0.08269682884216309\n",
      "5, 3800 loss: 0.08269682884216309\n",
      "5, 3900 loss: 0.08269682884216309\n",
      "5, 4000 loss: 0.08269682884216309\n",
      "5, 4100 loss: 0.08269682884216309\n",
      "5, 4200 loss: 0.08269682884216309\n",
      "5, 4300 loss: 0.08269682884216309\n",
      "5, 4400 loss: 0.08269682884216309\n",
      "5, 4500 loss: 0.08269682884216309\n",
      "5, 4600 loss: 0.08269682884216309\n",
      "5, 4700 loss: 0.08269682884216309\n",
      "5, 4800 loss: 0.08269682884216309\n",
      "5, 4900 loss: 0.08269682884216309\n",
      "5, 5000 loss: 0.08269682884216309\n",
      "5, 5100 loss: 0.08269682884216309\n",
      "5, 5200 loss: 0.08269682884216309\n",
      "5, 5300 loss: 0.08269682884216309\n",
      "5, 5400 loss: 0.08269682884216309\n",
      "5, 5500 loss: 0.08269682884216309\n",
      "5, 5600 loss: 0.08269682884216309\n",
      "5, 5700 loss: 0.08269682884216309\n",
      "5, 5800 loss: 0.08269682884216309\n",
      "5, 5900 loss: 0.08269682884216309\n",
      "5, 6000 loss: 0.08269682884216309\n",
      "5, 6100 loss: 0.08269682884216309\n",
      "5, 6200 loss: 0.08269682884216309\n",
      "5, 6300 loss: 0.08269682884216309\n",
      "5, 6400 loss: 0.08269682884216309\n",
      "5, 6500 loss: 0.08259682655334473\n",
      "trainging global model\n",
      "1, 100 loss: 0.008132616877555848\n",
      "1, 200 loss: 0.008132616877555848\n",
      "1, 300 loss: 0.0106326162815094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\bspli\\bspli\\partitioning.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ma = torch.tensor(means)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 400 loss: 0.005632616281509399\n",
      "1, 500 loss: 0.0031326165795326232\n",
      "1, 600 loss: 0.008132616877555848\n",
      "1, 700 loss: 0.005632616281509399\n",
      "1, 800 loss: 0.0081326162815094\n",
      "1, 900 loss: 0.0056326168775558474\n",
      "1, 1000 loss: 0.005632616281509399\n",
      "1, 1100 loss: 0.0081326162815094\n",
      "1, 1200 loss: 0.005632616281509399\n",
      "1, 1300 loss: 0.0056326168775558474\n",
      "1, 1400 loss: 0.0031326165795326232\n",
      "2, 100 loss: 0.005632616281509399\n",
      "2, 200 loss: 0.0031326165795326232\n",
      "2, 300 loss: 0.0106326162815094\n",
      "2, 400 loss: 0.0106326162815094\n",
      "2, 500 loss: 0.005632616281509399\n",
      "2, 600 loss: 0.008132616877555848\n",
      "2, 700 loss: 0.0031326165795326232\n",
      "2, 800 loss: 0.005632616281509399\n",
      "2, 900 loss: 0.0031326165795326232\n",
      "2, 1000 loss: 0.0081326162815094\n",
      "2, 1100 loss: 0.008132616877555848\n",
      "2, 1200 loss: 0.0106326162815094\n",
      "2, 1300 loss: 0.005632616281509399\n",
      "2, 1400 loss: 0.0056326168775558474\n",
      "3, 100 loss: 0.0081326162815094\n",
      "3, 200 loss: 0.005632616281509399\n",
      "3, 300 loss: 0.0106326162815094\n",
      "3, 400 loss: 0.0031326165795326232\n",
      "3, 500 loss: 0.005632616281509399\n",
      "3, 600 loss: 0.0106326162815094\n",
      "3, 700 loss: 0.0106326162815094\n",
      "3, 800 loss: 0.0031326165795326232\n",
      "3, 900 loss: 0.0081326162815094\n",
      "3, 1000 loss: 0.0081326162815094\n",
      "3, 1100 loss: 0.008132616877555848\n",
      "3, 1200 loss: 0.005632616281509399\n",
      "3, 1300 loss: 0.0081326162815094\n",
      "3, 1400 loss: 0.0081326162815094\n",
      "4, 100 loss: 0.005632616281509399\n",
      "4, 200 loss: 0.008132616877555848\n",
      "4, 300 loss: 0.013132616281509399\n",
      "4, 400 loss: 0.008132616877555848\n",
      "4, 500 loss: 0.0056326168775558474\n",
      "4, 600 loss: 0.0081326162815094\n",
      "4, 700 loss: 0.0106326162815094\n",
      "4, 800 loss: 0.008132616877555848\n",
      "4, 900 loss: 0.013132616281509399\n",
      "4, 1000 loss: 0.005632616281509399\n",
      "4, 1100 loss: 0.0031326165795326232\n",
      "4, 1200 loss: 0.005632616281509399\n",
      "4, 1300 loss: 0.008132616877555848\n",
      "4, 1400 loss: 0.008132616877555848\n",
      "5, 100 loss: 0.0056326168775558474\n",
      "5, 200 loss: 0.005632616281509399\n",
      "5, 300 loss: 0.0056326168775558474\n",
      "5, 400 loss: 0.008132616877555848\n",
      "5, 500 loss: 0.005632616281509399\n",
      "5, 600 loss: 0.0056326168775558474\n",
      "5, 700 loss: 0.0081326162815094\n",
      "5, 800 loss: 0.008132616877555848\n",
      "5, 900 loss: 0.008132616877555848\n",
      "5, 1000 loss: 0.0056326168775558474\n",
      "5, 1100 loss: 0.0056326168775558474\n",
      "5, 1200 loss: 0.0081326162815094\n",
      "5, 1300 loss: 0.008132616877555848\n",
      "5, 1400 loss: 0.008132616877555848\n",
      "finish\n",
      "local model len:2\n"
     ]
    }
   ],
   "source": [
    "sift_tensor = torch.from_numpy(sift)\n",
    "print(f'sift tensor shape: {sift_tensor.shape}')\n",
    "\n",
    "index = bspli.index.Indexing(gl_size=1000000, ll_size=300, random_partitioning=False)\n",
    "index.train(sift_tensor)\n",
    "\n",
    "print(f\"local model len:{len(index._l_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted local model: 1\n",
      "pred: tensor([ 17174,  50996,  38474,  49754,  35718,  40714,  47756, 782781,  47722,\n",
      "         32395,  19600,  10252, 743912, 626270,   9427, 816359, 706007, 599982,\n",
      "        653453,   7712, 866242, 323382, 961315, 130376, 136915, 648948,   4142,\n",
      "        425958, 914245, 560147, 985477, 287816, 334001, 651986, 247638,  10353,\n",
      "        387955, 352830,  20955, 755964, 364932, 448072, 494567, 246103, 536723,\n",
      "        182870,   7161,   9379, 457276, 759266, 559445, 415125, 506411, 979444,\n",
      "        323562,  47837, 748438, 825405, 359529, 715956,   8310, 485432, 334348,\n",
      "        773715, 250453, 283940, 366302, 986731, 239505, 895640, 384280, 624510,\n",
      "        647472, 763841, 172667, 153847, 393083, 960221, 816115, 652122, 829206,\n",
      "         21242, 839129, 895246, 408407, 855222, 314417, 878834, 904718, 710267,\n",
      "          7660, 369629, 845820, 774397, 842194, 915632,  49678, 864095,   9451,\n",
      "        146684], dtype=torch.int32)\n",
      "CPU times: total: 11.9 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qp = torch.from_numpy(sift[0])\n",
    "# print(qp)\n",
    "pred = index.query(qp, k=100)\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "\n",
    "def benchmark_knn_query(data, index, size=1000, k=100):\n",
    "    indices = np.random.choice(data.shape[0], size, replace=False)\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "    result.append((query_time/1000, cur_recall/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n"
     ]
    }
   ],
   "source": [
    "# recall(pred, FLAT_I)\n",
    "\n",
    "benchmark_knn_query(sift, index, size=1000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.025773720026016234, 6e-05), (0.005614554643630982, 8.999999999999999e-05)]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
