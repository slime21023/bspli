{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bspli'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbspli\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bspli'"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import faiss\n",
    "import time\n",
    "import numpy as np \n",
    "import bspli\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "sift = np.load(\"dataset/sift-128-euclidean.npy\")\n",
    "print(f'sift data shape: {sift.shape}')\n",
    "\n",
    "flat = faiss.IndexFlatL2(sift.shape[1])\n",
    "flat.add(sift)\n",
    "\n",
    "D, FLAT_I = flat.search(sift[0].reshape(1, sift.shape[1]), k=100) \n",
    "print(f'brute query: {FLAT_I}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift tensor shape: torch.Size([1000000, 128])\n",
      "torch.Size([343802, 129])\n",
      "torch.Size([656198, 129])\n",
      "first stage partitioning finish\n",
      "partitioning blocks : 2\n",
      "training local model\n",
      "1, 100 loss: 0.07621049404144287\n",
      "1, 200 loss: 0.07621051788330079\n",
      "1, 300 loss: 0.07621056556701661\n",
      "1, 400 loss: 0.07621056556701661\n",
      "1, 500 loss: 0.07621056556701661\n",
      "1, 600 loss: 0.07621056556701661\n",
      "1, 700 loss: 0.07621056556701661\n",
      "1, 800 loss: 0.07621056556701661\n",
      "1, 900 loss: 0.07621054172515869\n",
      "1, 1000 loss: 0.07621056556701661\n",
      "1, 1100 loss: 0.07621056556701661\n",
      "1, 1200 loss: 0.07621056556701661\n",
      "1, 1300 loss: 0.07621056556701661\n",
      "1, 1400 loss: 0.07621056556701661\n",
      "1, 1500 loss: 0.07621056556701661\n",
      "1, 1600 loss: 0.07621056556701661\n",
      "1, 1700 loss: 0.07621056556701661\n",
      "1, 1800 loss: 0.07611056327819825\n",
      "1, 1900 loss: 0.07621056079864502\n",
      "1, 2000 loss: 0.07621056079864502\n",
      "1, 2100 loss: 0.07621054649353028\n",
      "1, 2200 loss: 0.07621056079864502\n",
      "1, 2300 loss: 0.07621055126190185\n",
      "1, 2400 loss: 0.07621054649353028\n",
      "1, 2500 loss: 0.07621056556701661\n",
      "1, 2600 loss: 0.07621054172515869\n",
      "1, 2700 loss: 0.07621056556701661\n",
      "1, 2800 loss: 0.07621056556701661\n",
      "1, 2900 loss: 0.07621056556701661\n",
      "1, 3000 loss: 0.07621056556701661\n",
      "1, 3100 loss: 0.07621056079864502\n",
      "1, 3200 loss: 0.07611056327819825\n",
      "1, 3300 loss: 0.07621056556701661\n",
      "1, 3400 loss: 0.07621056556701661\n",
      "2, 100 loss: 0.07621056556701661\n",
      "2, 200 loss: 0.07621056079864502\n",
      "2, 300 loss: 0.07601056575775146\n",
      "2, 400 loss: 0.07621056556701661\n",
      "2, 500 loss: 0.07621056556701661\n",
      "2, 600 loss: 0.07621056556701661\n",
      "2, 700 loss: 0.07611056327819825\n",
      "2, 800 loss: 0.07611053466796874\n",
      "2, 900 loss: 0.07621056556701661\n",
      "2, 1000 loss: 0.07621056556701661\n",
      "2, 1100 loss: 0.07621055126190185\n",
      "2, 1200 loss: 0.07611056327819825\n",
      "2, 1300 loss: 0.07621055126190185\n",
      "2, 1400 loss: 0.07621056556701661\n",
      "2, 1500 loss: 0.07621056079864502\n",
      "2, 1600 loss: 0.07611053466796874\n",
      "2, 1700 loss: 0.07621054649353028\n",
      "2, 1800 loss: 0.07621056556701661\n",
      "2, 1900 loss: 0.07621055126190185\n",
      "2, 2000 loss: 0.07621054172515869\n",
      "2, 2100 loss: 0.07611050605773925\n",
      "2, 2200 loss: 0.0762105369567871\n",
      "2, 2300 loss: 0.07621056556701661\n",
      "2, 2400 loss: 0.07621056079864502\n",
      "2, 2500 loss: 0.07621056556701661\n",
      "2, 2600 loss: 0.07621055126190185\n",
      "2, 2700 loss: 0.07621052742004394\n",
      "2, 2800 loss: 0.07621054172515869\n",
      "2, 2900 loss: 0.07621056556701661\n",
      "2, 3000 loss: 0.07621056556701661\n",
      "2, 3100 loss: 0.07621056556701661\n",
      "2, 3200 loss: 0.07621056556701661\n",
      "2, 3300 loss: 0.07621054649353028\n",
      "2, 3400 loss: 0.07621054649353028\n",
      "3, 100 loss: 0.07621054172515869\n",
      "3, 200 loss: 0.07621056556701661\n",
      "3, 300 loss: 0.07621056556701661\n",
      "3, 400 loss: 0.07621056556701661\n",
      "3, 500 loss: 0.0762105369567871\n",
      "3, 600 loss: 0.07621056556701661\n",
      "3, 700 loss: 0.07621055126190185\n",
      "3, 800 loss: 0.07621054172515869\n",
      "3, 900 loss: 0.07621056556701661\n",
      "3, 1000 loss: 0.07621052265167236\n",
      "3, 1100 loss: 0.07621056556701661\n",
      "3, 1200 loss: 0.07621056556701661\n",
      "3, 1300 loss: 0.07621056556701661\n",
      "3, 1400 loss: 0.07621056556701661\n",
      "3, 1500 loss: 0.07611056327819825\n",
      "3, 1600 loss: 0.07621052265167236\n",
      "3, 1700 loss: 0.07621056556701661\n",
      "3, 1800 loss: 0.07621056556701661\n",
      "3, 1900 loss: 0.07621056079864502\n",
      "3, 2000 loss: 0.07621051788330079\n",
      "3, 2100 loss: 0.07621054172515869\n",
      "3, 2200 loss: 0.07621055126190185\n",
      "3, 2300 loss: 0.07621050834655761\n",
      "3, 2400 loss: 0.07621054172515869\n",
      "3, 2500 loss: 0.07621055126190185\n",
      "3, 2600 loss: 0.07621056079864502\n",
      "3, 2700 loss: 0.07621054172515869\n",
      "3, 2800 loss: 0.07621055126190185\n",
      "3, 2900 loss: 0.07621054172515869\n",
      "3, 3000 loss: 0.07621054172515869\n",
      "3, 3100 loss: 0.07621048450469971\n",
      "3, 3200 loss: 0.07621052265167236\n",
      "3, 3300 loss: 0.07621054172515869\n",
      "3, 3400 loss: 0.0761105489730835\n",
      "4, 100 loss: 0.07621056556701661\n",
      "4, 200 loss: 0.07621054649353028\n",
      "4, 300 loss: 0.07621055126190185\n",
      "4, 400 loss: 0.0762105369567871\n",
      "4, 500 loss: 0.07621055126190185\n",
      "4, 600 loss: 0.07621054172515869\n",
      "4, 700 loss: 0.07621049880981445\n",
      "4, 800 loss: 0.07621052742004394\n",
      "4, 900 loss: 0.07611048698425293\n",
      "4, 1000 loss: 0.07621050834655761\n",
      "4, 1100 loss: 0.07621050357818604\n",
      "4, 1200 loss: 0.07611051082611084\n",
      "4, 1300 loss: 0.07621054649353028\n",
      "4, 1400 loss: 0.07621050834655761\n",
      "4, 1500 loss: 0.07621045589447022\n",
      "4, 1600 loss: 0.07611051082611084\n",
      "4, 1700 loss: 0.0762104606628418\n",
      "4, 1800 loss: 0.07621046543121338\n",
      "4, 1900 loss: 0.07621054172515869\n",
      "4, 2000 loss: 0.07621047973632812\n",
      "4, 2100 loss: 0.07621049404144287\n",
      "4, 2200 loss: 0.07621055126190185\n",
      "4, 2300 loss: 0.07621052265167236\n",
      "4, 2400 loss: 0.07621056556701661\n",
      "4, 2500 loss: 0.07621054649353028\n",
      "4, 2600 loss: 0.07621054649353028\n",
      "4, 2700 loss: 0.07621056079864502\n",
      "4, 2800 loss: 0.07621055126190185\n",
      "4, 2900 loss: 0.07621052265167236\n",
      "4, 3000 loss: 0.07611052989959717\n",
      "4, 3100 loss: 0.07621054172515869\n",
      "4, 3200 loss: 0.07611055374145508\n",
      "4, 3300 loss: 0.07621054172515869\n",
      "4, 3400 loss: 0.07621055126190185\n",
      "5, 100 loss: 0.07621054649353028\n",
      "5, 200 loss: 0.07621054649353028\n",
      "5, 300 loss: 0.07621056079864502\n",
      "5, 400 loss: 0.07621054649353028\n",
      "5, 500 loss: 0.07621049880981445\n",
      "5, 600 loss: 0.07621050834655761\n",
      "5, 700 loss: 0.07621050834655761\n",
      "5, 800 loss: 0.07621051788330079\n",
      "5, 900 loss: 0.07621056556701661\n",
      "5, 1000 loss: 0.07621054649353028\n",
      "5, 1100 loss: 0.07621054172515869\n",
      "5, 1200 loss: 0.07621054649353028\n",
      "5, 1300 loss: 0.07621056079864502\n",
      "5, 1400 loss: 0.07611056327819825\n",
      "5, 1500 loss: 0.07611051559448243\n",
      "5, 1600 loss: 0.07621055126190185\n",
      "5, 1700 loss: 0.07621056079864502\n",
      "5, 1800 loss: 0.07621052265167236\n",
      "5, 1900 loss: 0.07621054172515869\n",
      "5, 2000 loss: 0.07621051788330079\n",
      "5, 2100 loss: 0.07621052742004394\n",
      "5, 2200 loss: 0.07621052742004394\n",
      "5, 2300 loss: 0.07621054172515869\n",
      "5, 2400 loss: 0.07621056556701661\n",
      "5, 2500 loss: 0.0762105369567871\n",
      "5, 2600 loss: 0.0762105369567871\n",
      "5, 2700 loss: 0.07621050357818604\n",
      "5, 2800 loss: 0.07621050834655761\n",
      "5, 2900 loss: 0.07621054649353028\n",
      "5, 3000 loss: 0.07621052265167236\n",
      "5, 3100 loss: 0.07621054172515869\n",
      "5, 3200 loss: 0.07621055126190185\n",
      "5, 3300 loss: 0.07621052742004394\n",
      "5, 3400 loss: 0.07621052265167236\n",
      "training local model\n",
      "1, 100 loss: 0.08269682884216309\n",
      "1, 200 loss: 0.08269682884216309\n",
      "1, 300 loss: 0.08269682884216309\n",
      "1, 400 loss: 0.08269682884216309\n",
      "1, 500 loss: 0.08269682884216309\n",
      "1, 600 loss: 0.08269682884216309\n",
      "1, 700 loss: 0.08269682884216309\n",
      "1, 800 loss: 0.08269682884216309\n",
      "1, 900 loss: 0.08269682884216309\n",
      "1, 1000 loss: 0.08269682884216309\n",
      "1, 1100 loss: 0.08269682884216309\n",
      "1, 1200 loss: 0.08269682884216309\n",
      "1, 1300 loss: 0.08269682884216309\n",
      "1, 1400 loss: 0.08269681930541992\n",
      "1, 1500 loss: 0.0826968002319336\n",
      "1, 1600 loss: 0.08269681930541992\n",
      "1, 1700 loss: 0.08269680976867676\n",
      "1, 1800 loss: 0.0826968002319336\n",
      "1, 1900 loss: 0.08269674301147462\n",
      "1, 2000 loss: 0.08269678115844727\n",
      "1, 2100 loss: 0.08269682884216309\n",
      "1, 2200 loss: 0.08269682884216309\n",
      "1, 2300 loss: 0.08269682884216309\n",
      "1, 2400 loss: 0.08269682884216309\n",
      "1, 2500 loss: 0.08269682884216309\n",
      "1, 2600 loss: 0.08269682884216309\n",
      "1, 2700 loss: 0.08269682884216309\n",
      "1, 2800 loss: 0.08259682655334473\n",
      "1, 2900 loss: 0.08269682884216309\n",
      "1, 3000 loss: 0.08269682884216309\n",
      "1, 3100 loss: 0.08269682884216309\n",
      "1, 3200 loss: 0.08269682884216309\n",
      "1, 3300 loss: 0.08259682655334473\n",
      "1, 3400 loss: 0.08269682884216309\n",
      "1, 3500 loss: 0.08269682884216309\n",
      "1, 3600 loss: 0.08259682655334473\n",
      "1, 3700 loss: 0.08269682884216309\n",
      "1, 3800 loss: 0.08269682884216309\n",
      "1, 3900 loss: 0.08269682884216309\n",
      "1, 4000 loss: 0.08259682655334473\n",
      "1, 4100 loss: 0.08269682884216309\n",
      "1, 4200 loss: 0.08269682884216309\n",
      "1, 4300 loss: 0.08269682884216309\n",
      "1, 4400 loss: 0.08269682884216309\n",
      "1, 4500 loss: 0.08269682884216309\n",
      "1, 4600 loss: 0.08269682884216309\n",
      "1, 4700 loss: 0.08269682884216309\n",
      "1, 4800 loss: 0.08259682655334473\n",
      "1, 4900 loss: 0.08269682884216309\n",
      "1, 5000 loss: 0.08269682884216309\n",
      "1, 5100 loss: 0.08269682884216309\n",
      "1, 5200 loss: 0.08269682884216309\n",
      "1, 5300 loss: 0.08269682884216309\n",
      "1, 5400 loss: 0.08269682884216309\n",
      "1, 5500 loss: 0.08269682884216309\n",
      "1, 5600 loss: 0.08269682884216309\n",
      "1, 5700 loss: 0.08269682884216309\n",
      "1, 5800 loss: 0.08269682884216309\n",
      "1, 5900 loss: 0.08269682884216309\n",
      "1, 6000 loss: 0.08269682884216309\n",
      "1, 6100 loss: 0.08269682884216309\n",
      "1, 6200 loss: 0.08259682655334473\n",
      "1, 6300 loss: 0.08269682884216309\n",
      "1, 6400 loss: 0.08269682884216309\n",
      "1, 6500 loss: 0.08269682884216309\n",
      "2, 100 loss: 0.08269682884216309\n",
      "2, 200 loss: 0.08269681930541992\n",
      "2, 300 loss: 0.08269682884216309\n",
      "2, 400 loss: 0.08269682884216309\n",
      "2, 500 loss: 0.08269682884216309\n",
      "2, 600 loss: 0.08269682884216309\n",
      "2, 700 loss: 0.08269682884216309\n",
      "2, 800 loss: 0.08269682884216309\n",
      "2, 900 loss: 0.08269682884216309\n",
      "2, 1000 loss: 0.08269682884216309\n",
      "2, 1100 loss: 0.08269682884216309\n",
      "2, 1200 loss: 0.08269682884216309\n",
      "2, 1300 loss: 0.08269682884216309\n",
      "2, 1400 loss: 0.08269682884216309\n",
      "2, 1500 loss: 0.08269682884216309\n",
      "2, 1600 loss: 0.08269682884216309\n",
      "2, 1700 loss: 0.08269682884216309\n",
      "2, 1800 loss: 0.08269682884216309\n",
      "2, 1900 loss: 0.08269682884216309\n",
      "2, 2000 loss: 0.08269682884216309\n",
      "2, 2100 loss: 0.08259682655334473\n",
      "2, 2200 loss: 0.08259682655334473\n",
      "2, 2300 loss: 0.08259682655334473\n",
      "2, 2400 loss: 0.08269682884216309\n",
      "2, 2500 loss: 0.08269682884216309\n",
      "2, 2600 loss: 0.08269682884216309\n",
      "2, 2700 loss: 0.08269682884216309\n",
      "2, 2800 loss: 0.08269682884216309\n",
      "2, 2900 loss: 0.08269682884216309\n",
      "2, 3000 loss: 0.08259682655334473\n",
      "2, 3100 loss: 0.08269682884216309\n",
      "2, 3200 loss: 0.08269682884216309\n",
      "2, 3300 loss: 0.08269682884216309\n",
      "2, 3400 loss: 0.08269682884216309\n",
      "2, 3500 loss: 0.08269682884216309\n",
      "2, 3600 loss: 0.08269682884216309\n",
      "2, 3700 loss: 0.08269682884216309\n",
      "2, 3800 loss: 0.08269682884216309\n",
      "2, 3900 loss: 0.08269682884216309\n",
      "2, 4000 loss: 0.08259682655334473\n",
      "2, 4100 loss: 0.08269682884216309\n",
      "2, 4200 loss: 0.08269682884216309\n",
      "2, 4300 loss: 0.08269682884216309\n",
      "2, 4400 loss: 0.08269682884216309\n",
      "2, 4500 loss: 0.08269682884216309\n",
      "2, 4600 loss: 0.08269682884216309\n",
      "2, 4700 loss: 0.08269682884216309\n",
      "2, 4800 loss: 0.08269682884216309\n",
      "2, 4900 loss: 0.08269682884216309\n",
      "2, 5000 loss: 0.08269682884216309\n",
      "2, 5100 loss: 0.08269682884216309\n",
      "2, 5200 loss: 0.08269682884216309\n",
      "2, 5300 loss: 0.08269682884216309\n",
      "2, 5400 loss: 0.08269682884216309\n",
      "2, 5500 loss: 0.08269682884216309\n",
      "2, 5600 loss: 0.08269682884216309\n",
      "2, 5700 loss: 0.08259682655334473\n",
      "2, 5800 loss: 0.08269682884216309\n",
      "2, 5900 loss: 0.08269682884216309\n",
      "2, 6000 loss: 0.08269682884216309\n",
      "2, 6100 loss: 0.08269682884216309\n",
      "2, 6200 loss: 0.08269682884216309\n",
      "2, 6300 loss: 0.08259682655334473\n",
      "2, 6400 loss: 0.08269682884216309\n",
      "2, 6500 loss: 0.08269682884216309\n",
      "3, 100 loss: 0.08269682884216309\n",
      "3, 200 loss: 0.08269682884216309\n",
      "3, 300 loss: 0.08269682884216309\n",
      "3, 400 loss: 0.08269682884216309\n",
      "3, 500 loss: 0.08269682884216309\n",
      "3, 600 loss: 0.08269682884216309\n",
      "3, 700 loss: 0.08269682884216309\n",
      "3, 800 loss: 0.08269682884216309\n",
      "3, 900 loss: 0.08269682884216309\n",
      "3, 1000 loss: 0.08269682884216309\n",
      "3, 1100 loss: 0.08269682884216309\n",
      "3, 1200 loss: 0.08269682884216309\n",
      "3, 1300 loss: 0.08269682884216309\n",
      "3, 1400 loss: 0.08269682884216309\n",
      "3, 1500 loss: 0.08269682884216309\n",
      "3, 1600 loss: 0.08269682884216309\n",
      "3, 1700 loss: 0.08269682884216309\n",
      "3, 1800 loss: 0.08269682884216309\n",
      "3, 1900 loss: 0.08259682655334473\n",
      "3, 2000 loss: 0.08269682884216309\n",
      "3, 2100 loss: 0.08269682884216309\n",
      "3, 2200 loss: 0.08269682884216309\n",
      "3, 2300 loss: 0.08259682655334473\n",
      "3, 2400 loss: 0.08269682884216309\n",
      "3, 2500 loss: 0.08269682884216309\n",
      "3, 2600 loss: 0.08269682884216309\n",
      "3, 2700 loss: 0.08269682884216309\n",
      "3, 2800 loss: 0.08269682884216309\n",
      "3, 2900 loss: 0.08269682884216309\n",
      "3, 3000 loss: 0.08269682884216309\n",
      "3, 3100 loss: 0.08269682884216309\n",
      "3, 3200 loss: 0.08269682884216309\n",
      "3, 3300 loss: 0.08269682884216309\n",
      "3, 3400 loss: 0.08269682884216309\n",
      "3, 3500 loss: 0.08259682655334473\n",
      "3, 3600 loss: 0.08269682884216309\n",
      "3, 3700 loss: 0.08269682884216309\n",
      "3, 3800 loss: 0.08269680976867676\n",
      "3, 3900 loss: 0.08269682884216309\n",
      "3, 4000 loss: 0.08269682884216309\n",
      "3, 4100 loss: 0.08269682884216309\n",
      "3, 4200 loss: 0.08269682884216309\n",
      "3, 4300 loss: 0.08269682884216309\n",
      "3, 4400 loss: 0.08269682884216309\n",
      "3, 4500 loss: 0.08269682884216309\n",
      "3, 4600 loss: 0.08269682884216309\n",
      "3, 4700 loss: 0.08269682884216309\n",
      "3, 4800 loss: 0.08269682884216309\n",
      "3, 4900 loss: 0.08269682884216309\n",
      "3, 5000 loss: 0.08269682884216309\n",
      "3, 5100 loss: 0.08269682884216309\n",
      "3, 5200 loss: 0.08259682655334473\n",
      "3, 5300 loss: 0.08269682884216309\n",
      "3, 5400 loss: 0.08269682884216309\n",
      "3, 5500 loss: 0.08269682884216309\n",
      "3, 5600 loss: 0.08269682884216309\n",
      "3, 5700 loss: 0.08269682884216309\n",
      "3, 5800 loss: 0.08269682884216309\n",
      "3, 5900 loss: 0.08269682884216309\n",
      "3, 6000 loss: 0.08269682884216309\n",
      "3, 6100 loss: 0.08269682884216309\n",
      "3, 6200 loss: 0.08259682655334473\n",
      "3, 6300 loss: 0.08269682884216309\n",
      "3, 6400 loss: 0.08269682884216309\n",
      "3, 6500 loss: 0.08269682884216309\n",
      "4, 100 loss: 0.08269682884216309\n",
      "4, 200 loss: 0.08269682884216309\n",
      "4, 300 loss: 0.08269682884216309\n",
      "4, 400 loss: 0.08269682884216309\n",
      "4, 500 loss: 0.08269682884216309\n",
      "4, 600 loss: 0.08269682884216309\n",
      "4, 700 loss: 0.08269682884216309\n",
      "4, 800 loss: 0.08269682884216309\n",
      "4, 900 loss: 0.08259682655334473\n",
      "4, 1000 loss: 0.08269682884216309\n",
      "4, 1100 loss: 0.08269682884216309\n",
      "4, 1200 loss: 0.08269682884216309\n",
      "4, 1300 loss: 0.08269682884216309\n",
      "4, 1400 loss: 0.08269682884216309\n",
      "4, 1500 loss: 0.08269682884216309\n",
      "4, 1600 loss: 0.08269682884216309\n",
      "4, 1700 loss: 0.08269682884216309\n",
      "4, 1800 loss: 0.08269682884216309\n",
      "4, 1900 loss: 0.08269682884216309\n",
      "4, 2000 loss: 0.08269682884216309\n",
      "4, 2100 loss: 0.08269682884216309\n",
      "4, 2200 loss: 0.08269682884216309\n",
      "4, 2300 loss: 0.08269682884216309\n",
      "4, 2400 loss: 0.08269682884216309\n",
      "4, 2500 loss: 0.08269682884216309\n",
      "4, 2600 loss: 0.08269682884216309\n",
      "4, 2700 loss: 0.08269682884216309\n",
      "4, 2800 loss: 0.08269682884216309\n",
      "4, 2900 loss: 0.08269682884216309\n",
      "4, 3000 loss: 0.08259682655334473\n",
      "4, 3100 loss: 0.08269682884216309\n",
      "4, 3200 loss: 0.08269682884216309\n",
      "4, 3300 loss: 0.08269682884216309\n",
      "4, 3400 loss: 0.08269682884216309\n",
      "4, 3500 loss: 0.08269682884216309\n",
      "4, 3600 loss: 0.08259682655334473\n",
      "4, 3700 loss: 0.08269682884216309\n",
      "4, 3800 loss: 0.08269682884216309\n",
      "4, 3900 loss: 0.08269682884216309\n",
      "4, 4000 loss: 0.08269682884216309\n",
      "4, 4100 loss: 0.08269682884216309\n",
      "4, 4200 loss: 0.08269682884216309\n",
      "4, 4300 loss: 0.08269682884216309\n",
      "4, 4400 loss: 0.08269682884216309\n",
      "4, 4500 loss: 0.08269682884216309\n",
      "4, 4600 loss: 0.08269682884216309\n",
      "4, 4700 loss: 0.08269682884216309\n",
      "4, 4800 loss: 0.08269682884216309\n",
      "4, 4900 loss: 0.08269682884216309\n",
      "4, 5000 loss: 0.08269682884216309\n",
      "4, 5100 loss: 0.08259682655334473\n",
      "4, 5200 loss: 0.08269682884216309\n",
      "4, 5300 loss: 0.08269682884216309\n",
      "4, 5400 loss: 0.08269682884216309\n",
      "4, 5500 loss: 0.08269682884216309\n",
      "4, 5600 loss: 0.08269682884216309\n",
      "4, 5700 loss: 0.08259682655334473\n",
      "4, 5800 loss: 0.08269682884216309\n",
      "4, 5900 loss: 0.08269682884216309\n",
      "4, 6000 loss: 0.08269682884216309\n",
      "4, 6100 loss: 0.08269682884216309\n",
      "4, 6200 loss: 0.08269682884216309\n",
      "4, 6300 loss: 0.08269682884216309\n",
      "4, 6400 loss: 0.08269682884216309\n",
      "4, 6500 loss: 0.08269682884216309\n",
      "5, 100 loss: 0.08269682884216309\n",
      "5, 200 loss: 0.08269682884216309\n",
      "5, 300 loss: 0.08269682884216309\n",
      "5, 400 loss: 0.08269682884216309\n",
      "5, 500 loss: 0.08269682884216309\n",
      "5, 600 loss: 0.08269682884216309\n",
      "5, 700 loss: 0.08269682884216309\n",
      "5, 800 loss: 0.08269682884216309\n",
      "5, 900 loss: 0.08269682884216309\n",
      "5, 1000 loss: 0.08269682884216309\n",
      "5, 1100 loss: 0.08269682884216309\n",
      "5, 1200 loss: 0.08269682884216309\n",
      "5, 1300 loss: 0.08269682884216309\n",
      "5, 1400 loss: 0.08269681930541992\n",
      "5, 1500 loss: 0.08269682884216309\n",
      "5, 1600 loss: 0.08269682884216309\n",
      "5, 1700 loss: 0.08269682884216309\n",
      "5, 1800 loss: 0.08269682884216309\n",
      "5, 1900 loss: 0.08269682884216309\n",
      "5, 2000 loss: 0.08269682884216309\n",
      "5, 2100 loss: 0.08269682884216309\n",
      "5, 2200 loss: 0.08269682884216309\n",
      "5, 2300 loss: 0.08269681930541992\n",
      "5, 2400 loss: 0.08269682884216309\n",
      "5, 2500 loss: 0.08269682884216309\n",
      "5, 2600 loss: 0.08269682884216309\n",
      "5, 2700 loss: 0.08269682884216309\n",
      "5, 2800 loss: 0.08269682884216309\n",
      "5, 2900 loss: 0.08269682884216309\n",
      "5, 3000 loss: 0.08269682884216309\n",
      "5, 3100 loss: 0.08269682884216309\n",
      "5, 3200 loss: 0.08269682884216309\n",
      "5, 3300 loss: 0.08269681930541992\n",
      "5, 3400 loss: 0.08269682884216309\n",
      "5, 3500 loss: 0.08269682884216309\n",
      "5, 3600 loss: 0.08269682884216309\n",
      "5, 3700 loss: 0.08269682884216309\n",
      "5, 3800 loss: 0.08269682884216309\n",
      "5, 3900 loss: 0.08269682884216309\n",
      "5, 4000 loss: 0.08269682884216309\n",
      "5, 4100 loss: 0.08269682884216309\n",
      "5, 4200 loss: 0.08269682884216309\n",
      "5, 4300 loss: 0.08269682884216309\n",
      "5, 4400 loss: 0.08269682884216309\n",
      "5, 4500 loss: 0.08269682884216309\n",
      "5, 4600 loss: 0.08269682884216309\n",
      "5, 4700 loss: 0.08269682884216309\n",
      "5, 4800 loss: 0.08269682884216309\n",
      "5, 4900 loss: 0.08269682884216309\n",
      "5, 5000 loss: 0.08269682884216309\n",
      "5, 5100 loss: 0.08269682884216309\n",
      "5, 5200 loss: 0.08269682884216309\n",
      "5, 5300 loss: 0.08269682884216309\n",
      "5, 5400 loss: 0.08269682884216309\n",
      "5, 5500 loss: 0.08269682884216309\n",
      "5, 5600 loss: 0.08269682884216309\n",
      "5, 5700 loss: 0.08269682884216309\n",
      "5, 5800 loss: 0.08269682884216309\n",
      "5, 5900 loss: 0.08269682884216309\n",
      "5, 6000 loss: 0.08269682884216309\n",
      "5, 6100 loss: 0.08269682884216309\n",
      "5, 6200 loss: 0.08269682884216309\n",
      "5, 6300 loss: 0.08269682884216309\n",
      "5, 6400 loss: 0.08269682884216309\n",
      "5, 6500 loss: 0.08259682655334473\n",
      "trainging global model\n",
      "1, 100 loss: 0.008132616877555848\n",
      "1, 200 loss: 0.008132616877555848\n",
      "1, 300 loss: 0.0106326162815094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\study\\bspli\\bspli\\partitioning.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ma = torch.tensor(means)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 400 loss: 0.005632616281509399\n",
      "1, 500 loss: 0.0031326165795326232\n",
      "1, 600 loss: 0.008132616877555848\n",
      "1, 700 loss: 0.005632616281509399\n",
      "1, 800 loss: 0.0081326162815094\n",
      "1, 900 loss: 0.0056326168775558474\n",
      "1, 1000 loss: 0.005632616281509399\n",
      "1, 1100 loss: 0.0081326162815094\n",
      "1, 1200 loss: 0.005632616281509399\n",
      "1, 1300 loss: 0.0056326168775558474\n",
      "1, 1400 loss: 0.0031326165795326232\n",
      "2, 100 loss: 0.005632616281509399\n",
      "2, 200 loss: 0.0031326165795326232\n",
      "2, 300 loss: 0.0106326162815094\n",
      "2, 400 loss: 0.0106326162815094\n",
      "2, 500 loss: 0.005632616281509399\n",
      "2, 600 loss: 0.008132616877555848\n",
      "2, 700 loss: 0.0031326165795326232\n",
      "2, 800 loss: 0.005632616281509399\n",
      "2, 900 loss: 0.0031326165795326232\n",
      "2, 1000 loss: 0.0081326162815094\n",
      "2, 1100 loss: 0.008132616877555848\n",
      "2, 1200 loss: 0.0106326162815094\n",
      "2, 1300 loss: 0.005632616281509399\n",
      "2, 1400 loss: 0.0056326168775558474\n",
      "3, 100 loss: 0.0081326162815094\n",
      "3, 200 loss: 0.005632616281509399\n",
      "3, 300 loss: 0.0106326162815094\n",
      "3, 400 loss: 0.0031326165795326232\n",
      "3, 500 loss: 0.005632616281509399\n",
      "3, 600 loss: 0.0106326162815094\n",
      "3, 700 loss: 0.0106326162815094\n",
      "3, 800 loss: 0.0031326165795326232\n",
      "3, 900 loss: 0.0081326162815094\n",
      "3, 1000 loss: 0.0081326162815094\n",
      "3, 1100 loss: 0.008132616877555848\n",
      "3, 1200 loss: 0.005632616281509399\n",
      "3, 1300 loss: 0.0081326162815094\n",
      "3, 1400 loss: 0.0081326162815094\n",
      "4, 100 loss: 0.005632616281509399\n",
      "4, 200 loss: 0.008132616877555848\n",
      "4, 300 loss: 0.013132616281509399\n",
      "4, 400 loss: 0.008132616877555848\n",
      "4, 500 loss: 0.0056326168775558474\n",
      "4, 600 loss: 0.0081326162815094\n",
      "4, 700 loss: 0.0106326162815094\n",
      "4, 800 loss: 0.008132616877555848\n",
      "4, 900 loss: 0.013132616281509399\n",
      "4, 1000 loss: 0.005632616281509399\n",
      "4, 1100 loss: 0.0031326165795326232\n",
      "4, 1200 loss: 0.005632616281509399\n",
      "4, 1300 loss: 0.008132616877555848\n",
      "4, 1400 loss: 0.008132616877555848\n",
      "5, 100 loss: 0.0056326168775558474\n",
      "5, 200 loss: 0.005632616281509399\n",
      "5, 300 loss: 0.0056326168775558474\n",
      "5, 400 loss: 0.008132616877555848\n",
      "5, 500 loss: 0.005632616281509399\n",
      "5, 600 loss: 0.0056326168775558474\n",
      "5, 700 loss: 0.0081326162815094\n",
      "5, 800 loss: 0.008132616877555848\n",
      "5, 900 loss: 0.008132616877555848\n",
      "5, 1000 loss: 0.0056326168775558474\n",
      "5, 1100 loss: 0.0056326168775558474\n",
      "5, 1200 loss: 0.0081326162815094\n",
      "5, 1300 loss: 0.008132616877555848\n",
      "5, 1400 loss: 0.008132616877555848\n",
      "finish\n",
      "local model len:2\n"
     ]
    }
   ],
   "source": [
    "sift_tensor = torch.from_numpy(sift)\n",
    "print(f'sift tensor shape: {sift_tensor.shape}')\n",
    "\n",
    "index = bspli.index.Indexing(gl_size=1000000, ll_size=300, random_partitioning=False)\n",
    "index.train(sift_tensor)\n",
    "\n",
    "print(f\"local model len:{len(index._l_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted local model: 1\n",
      "pred: tensor([ 17174,  50996,  38474,  49754,  35718,  40714,  47756, 782781,  47722,\n",
      "         32395,  19600,  10252, 743912, 626270,   9427, 816359, 706007, 599982,\n",
      "        653453,   7712, 866242, 323382, 961315, 130376, 136915, 648948,   4142,\n",
      "        425958, 914245, 560147, 985477, 287816, 334001, 651986, 247638,  10353,\n",
      "        387955, 352830,  20955, 755964, 364932, 448072, 494567, 246103, 536723,\n",
      "        182870,   7161,   9379, 457276, 759266, 559445, 415125, 506411, 979444,\n",
      "        323562,  47837, 748438, 825405, 359529, 715956,   8310, 485432, 334348,\n",
      "        773715, 250453, 283940, 366302, 986731, 239505, 895640, 384280, 624510,\n",
      "        647472, 763841, 172667, 153847, 393083, 960221, 816115, 652122, 829206,\n",
      "         21242, 839129, 895246, 408407, 855222, 314417, 878834, 904718, 710267,\n",
      "          7660, 369629, 845820, 774397, 842194, 915632,  49678, 864095,   9451,\n",
      "        146684], dtype=torch.int32)\n",
      "CPU times: total: 11.9 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qp = torch.from_numpy(sift[0])\n",
    "# print(qp)\n",
    "pred = index.query(qp, k=100)\n",
    "pred = pred.to(torch.int)\n",
    "print(f\"pred: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def recall(pred, true):\n",
    "    x = np.isin(pred, true)\n",
    "    return x.sum() / true.size\n",
    "\n",
    "\n",
    "def benchmark_knn_query(data, index, size=1000, k=100):\n",
    "    indices = np.random.choice(data.shape[0], size, replace=False)\n",
    "    query_time = 0\n",
    "    cur_recall = 0\n",
    "\n",
    "    # query\n",
    "    for i in indices:\n",
    "        q = torch.from_numpy(data[i])\n",
    "        start = time.time()\n",
    "        qk = index.query(q, k=100)\n",
    "        query_time += (time.time() - start)\n",
    "        D, FLAT_I = flat.search(data[i].reshape(1, data.shape[1]), k=k) \n",
    "        cur_recall += recall(qk, FLAT_I)\n",
    "    result.append((query_time/1000, cur_recall/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n",
      "predicted local model: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# recall(pred, FLAT_I)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m benchmark_knn_query(sift, index, size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, k\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mbenchmark_knn_query\u001b[1;34m(data, index, size, k)\u001b[0m\n\u001b[0;32m     15\u001b[0m q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(data[i])\n\u001b[0;32m     16\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 17\u001b[0m qk \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mquery(q, k\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     18\u001b[0m query_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start)\n\u001b[0;32m     19\u001b[0m D, FLAT_I \u001b[39m=\u001b[39m flat\u001b[39m.\u001b[39msearch(data[i]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), k\u001b[39m=\u001b[39mk) \n",
      "File \u001b[1;32md:\\study\\bspli\\bspli\\index.py:79\u001b[0m, in \u001b[0;36mquery\u001b[1;34m(self, qp, k)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery\u001b[39m(\u001b[39mself\u001b[39m, qp, k):\n\u001b[0;32m     76\u001b[0m     \u001b[39m# qp = qp.reshape(1, qp.shape[0])\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[39m# predict the query point in which local model\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_g_model\u001b[39m.\u001b[39mquery(qp)\n\u001b[1;32m---> 79\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredicted local model: \u001b[39m\u001b[39m{\u001b[39;00mpred\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m     \u001b[39m# get the topk result indices\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_l_model[pred]\u001b[39m.\u001b[39mquery(qp, k)\n",
      "File \u001b[1;32md:\\study\\bspli\\bspli\\lindex.py:71\u001b[0m, in \u001b[0;36mLIndexing.query\u001b[1;34m(self, qp, k)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m         \u001b[39mreturn\u001b[39;00m search_points\n\u001b[1;32m---> 71\u001b[0m search_points \u001b[39m=\u001b[39m get_search_block(\n\u001b[0;32m     72\u001b[0m     mininal\u001b[39m=\u001b[39;49mmin_block_number,\n\u001b[0;32m     73\u001b[0m     maximum\u001b[39m=\u001b[39;49mmax_block_number,\n\u001b[0;32m     74\u001b[0m     k\u001b[39m=\u001b[39;49mk\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     77\u001b[0m \u001b[39m# print(f\"search_points shape: {search_points.shape}\")\u001b[39;00m\n\u001b[0;32m     79\u001b[0m norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(search_points \u001b[39m-\u001b[39m qp, dim\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32md:\\study\\bspli\\bspli\\lindex.py:66\u001b[0m, in \u001b[0;36mLIndexing.query.<locals>.get_search_block\u001b[1;34m(mininal, maximum, k)\u001b[0m\n\u001b[0;32m     64\u001b[0m     mininal \u001b[39m=\u001b[39m mininal \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m mininal \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m     65\u001b[0m     maximum \u001b[39m=\u001b[39m maximum \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m maximum \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m get_search_block(mininal, maximum, k)\n\u001b[0;32m     67\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m search_points\n",
      "File \u001b[1;32md:\\study\\bspli\\bspli\\lindex.py:66\u001b[0m, in \u001b[0;36mLIndexing.query.<locals>.get_search_block\u001b[1;34m(mininal, maximum, k)\u001b[0m\n\u001b[0;32m     64\u001b[0m     mininal \u001b[39m=\u001b[39m mininal \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m mininal \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m     65\u001b[0m     maximum \u001b[39m=\u001b[39m maximum \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m maximum \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m get_search_block(mininal, maximum, k)\n\u001b[0;32m     67\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m search_points\n",
      "    \u001b[1;31m[... skipping similar frames: LIndexing.query.<locals>.get_search_block at line 66 (979 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\study\\bspli\\bspli\\lindex.py:66\u001b[0m, in \u001b[0;36mLIndexing.query.<locals>.get_search_block\u001b[1;34m(mininal, maximum, k)\u001b[0m\n\u001b[0;32m     64\u001b[0m     mininal \u001b[39m=\u001b[39m mininal \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m mininal \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m     65\u001b[0m     maximum \u001b[39m=\u001b[39m maximum \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m maximum \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m get_search_block(mininal, maximum, k)\n\u001b[0;32m     67\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m search_points\n",
      "File \u001b[1;32md:\\study\\bspli\\bspli\\lindex.py:56\u001b[0m, in \u001b[0;36mLIndexing.query.<locals>.get_search_block\u001b[1;34m(mininal, maximum, k)\u001b[0m\n\u001b[0;32m     53\u001b[0m max_block_number \u001b[39m=\u001b[39m pred \u001b[39m+\u001b[39m error_block_size\n\u001b[0;32m     54\u001b[0m max_block_number \u001b[39m=\u001b[39m max_block_number \u001b[39mif\u001b[39;00m max_block_number \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes\n\u001b[1;32m---> 56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_search_block\u001b[39m(mininal, maximum, k: \u001b[39mint\u001b[39m):\n\u001b[0;32m     57\u001b[0m     search_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_data[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     58\u001b[0m     search_points \u001b[39m=\u001b[39m search_points[\n\u001b[0;32m     59\u001b[0m         (search_points[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m mininal) \u001b[39m&\u001b[39m \n\u001b[0;32m     60\u001b[0m         (search_points[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m maximum)\n\u001b[0;32m     61\u001b[0m     ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# recall(pred, FLAT_I)\n",
    "\n",
    "benchmark_knn_query(sift, index, size=1000, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.025773720026016234, 6e-05), (0.005614554643630982, 8.999999999999999e-05)]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
